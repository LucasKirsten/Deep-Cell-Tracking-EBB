{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%cd /workdir/msc/RotationDetection/libs/utils/cython_utils\n",
    "!rm *.so\n",
    "!rm *.c\n",
    "!rm *.cpp\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%cd /workdir/msc/RotationDetection/libs/utils/\n",
    "!rm *.so\n",
    "!rm *.c\n",
    "!rm *.cpp\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET='Fluo-N2DH-SIM+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir\n",
      "Archive:  Fluo-N2DH-SIM+.zip\n",
      "   creating: Fluo-N2DH-SIM+/01/\n",
      "   creating: Fluo-N2DH-SIM+/01/images/\n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t000.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t001.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t002.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t003.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t004.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t005.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t006.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t007.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t008.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t009.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t010.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t011.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t012.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t013.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t014.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t015.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t016.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t017.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t018.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t019.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t020.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t021.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t022.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t023.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t024.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t025.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t026.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t027.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t028.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t029.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t030.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t031.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t032.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t033.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t034.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t035.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t036.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t037.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t038.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t039.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t040.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t041.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t042.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t043.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t044.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t045.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t046.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t047.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t048.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t049.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t050.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t051.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t052.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t053.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t054.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t055.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t056.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t057.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t058.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t059.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t060.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t061.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t062.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t063.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01/images/t064.tif  \n",
      "   creating: Fluo-N2DH-SIM+/01_GT/\n",
      "   creating: Fluo-N2DH-SIM+/01_GT/SEG/\n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg000.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg001.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg002.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg003.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg004.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg005.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg006.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg007.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg008.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg009.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg010.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg011.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg012.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg013.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg014.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg015.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg016.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg017.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg018.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg019.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg020.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg021.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg022.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg023.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg024.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg025.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg026.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg027.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg028.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg029.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg030.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg031.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg032.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg033.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg034.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg035.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg036.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg037.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg038.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg039.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg040.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg041.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg042.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg043.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg044.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg045.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg046.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg047.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg048.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg049.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg050.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg051.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg052.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg053.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg054.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg055.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg056.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg057.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg058.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg059.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg060.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg061.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg062.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg063.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/SEG/man_seg064.tif  \n",
      "   creating: Fluo-N2DH-SIM+/01_GT/TRA/\n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track.txt  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track000.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track001.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track002.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track003.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track004.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track005.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track006.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track007.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track008.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track009.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track010.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track011.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track012.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track013.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track014.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track015.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track016.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track017.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track018.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track019.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track020.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track021.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track022.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track023.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track024.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track025.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track026.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track027.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track028.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track029.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track030.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track031.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track032.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track033.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track034.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track035.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track036.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track037.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track038.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track039.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track040.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track041.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track042.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track043.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track044.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track045.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track046.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track047.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track048.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track049.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track050.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track051.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track052.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track053.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track054.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track055.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track056.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track057.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track058.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track059.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track060.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track061.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track062.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track063.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/01_GT/TRA/man_track064.tif  \n",
      "   creating: Fluo-N2DH-SIM+/02/\n",
      "   creating: Fluo-N2DH-SIM+/02/images/\n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t000.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t001.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t002.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t003.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t004.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t005.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t006.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t007.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t008.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t009.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t010.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t011.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t012.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t013.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t014.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t015.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t016.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t017.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t018.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t019.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t020.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t021.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t022.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t023.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t024.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t025.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t026.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t027.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t028.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t029.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t030.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t031.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t032.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t033.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t034.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t035.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t036.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t037.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t038.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t039.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t040.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t041.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t042.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t043.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t044.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t045.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t046.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t047.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t048.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t049.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t050.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t051.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t052.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t053.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t054.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t055.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t056.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t057.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t058.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t059.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t060.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t061.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t062.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t063.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t064.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t065.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t066.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t067.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t068.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t069.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t070.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t071.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t072.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t073.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t074.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t075.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t076.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t077.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t078.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t079.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t080.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t081.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t082.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t083.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t084.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t085.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t086.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t087.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t088.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t089.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t090.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t091.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t092.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t093.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t094.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t095.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t096.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t097.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t098.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t099.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t100.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t101.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t102.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t103.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t104.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t105.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t106.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t107.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t108.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t109.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t110.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t111.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t112.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t113.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t114.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t115.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t116.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t117.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t118.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t119.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t120.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t121.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t122.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t123.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t124.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t125.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t126.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t127.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t128.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t129.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t130.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t131.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t132.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t133.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t134.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t135.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t136.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t137.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t138.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t139.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t140.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t141.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t142.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t143.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t144.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t145.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t146.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t147.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t148.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02/images/t149.tif  \n",
      "   creating: Fluo-N2DH-SIM+/02_GT/\n",
      "   creating: Fluo-N2DH-SIM+/02_GT/SEG/\n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg000.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg001.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg002.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg003.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg004.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg005.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg006.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg007.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg008.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg009.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg010.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg011.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg012.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg013.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg014.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg015.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg016.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg017.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg018.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg019.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg020.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg021.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg022.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg023.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg024.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg025.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg026.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg027.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg028.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg029.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg030.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg031.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg032.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg033.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg034.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg035.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg036.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg037.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg038.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg039.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg040.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg041.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg042.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg043.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg044.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg045.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg046.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg047.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg048.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg049.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg050.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg051.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg052.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg053.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg054.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg055.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg056.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg057.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg058.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg059.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg060.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg061.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg062.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg063.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg064.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg065.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg066.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg067.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg068.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg069.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg070.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg071.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg072.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg073.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg074.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg075.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg076.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg077.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg078.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg079.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg080.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg081.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg082.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg083.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg084.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg085.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg086.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg087.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg088.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg089.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg090.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg091.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg092.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg093.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg094.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg095.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg096.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg097.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg098.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg099.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg100.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg101.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg102.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg103.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg104.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg105.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg106.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg107.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg108.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg109.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg110.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg111.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg112.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg113.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg114.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg115.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg116.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg117.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg118.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg119.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg120.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg121.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg122.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg123.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg124.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg125.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg126.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg127.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg128.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg129.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg130.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg131.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg132.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg133.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg134.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg135.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg136.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg137.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg138.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg139.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg140.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg141.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg142.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg143.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg144.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg145.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg146.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg147.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg148.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/SEG/man_seg149.tif  \n",
      "   creating: Fluo-N2DH-SIM+/02_GT/TRA/\n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track.txt  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track000.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track001.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track002.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track003.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track004.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track005.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track006.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track007.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track008.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track009.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track010.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track011.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track012.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track013.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track014.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track015.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track016.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track017.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track018.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track019.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track020.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track021.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track022.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track023.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track024.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track025.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track026.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track027.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track028.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track029.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track030.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track031.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track032.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track033.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track034.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track035.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track036.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track037.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track038.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track039.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track040.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track041.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track042.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track043.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track044.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track045.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track046.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track047.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track048.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track049.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track050.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track051.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track052.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track053.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track054.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track055.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track056.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track057.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track058.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track059.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track060.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track061.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track062.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track063.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track064.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track065.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track066.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track067.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track068.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track069.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track070.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track071.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track072.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track073.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track074.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track075.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track076.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track077.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track078.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track079.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track080.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track081.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track082.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track083.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track084.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track085.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track086.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track087.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track088.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track089.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track090.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track091.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track092.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track093.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track094.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track095.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track096.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track097.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track098.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track099.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track100.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track101.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track102.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track103.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track104.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track105.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track106.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track107.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track108.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track109.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track110.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track111.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track112.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track113.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track114.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track115.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track116.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track117.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track118.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track119.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track120.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track121.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track122.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track123.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track124.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track125.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track126.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track127.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track128.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track129.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track130.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track131.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track132.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track133.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track134.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track135.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track136.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track137.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track138.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track139.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track140.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track141.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track142.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track143.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track144.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track145.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track146.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track147.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track148.tif  \n",
      "  inflating: Fluo-N2DH-SIM+/02_GT/TRA/man_track149.tif  \n"
     ]
    }
   ],
   "source": [
    "%cd /workdir\n",
    "!rm -r {DATASET}\n",
    "!unzip {DATASET}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/SW/RotationDetection/track_by_detection\n",
      "Namespace(augment=False, augment_size=None, consider_mitoses=False, copy_tra2seg=False, dataset='Fluo-N2DH-SIM+', lineage='01', path_root='/workdir')\n",
      "100%|███████████████████████████████████████████| 65/65 [00:04<00:00, 14.18it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/SW/RotationDetection/track_by_detection\n",
    "!python convert2obb.py \\\n",
    "--dataset {DATASET} \\\n",
    "--lineage 01 \\\n",
    "--path_root /workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change train and test paths inside the script\n",
    "%cd /workdir/SW/RotationDetection/dataloader/dataset/UFRGS_CELL\n",
    "!python convert_ann2dota.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/SW/RotationDetection/dataloader/dataset/UFRGS_CELL\n",
      "Converting images to jpg: 100%|███████████████| 150/150 [00:02<00:00, 65.91it/s]\n",
      "/workdir/Fluo-N2DH-SIM+/02/images\n",
      "MEAN:  23.154136710273022\n",
      "STD:  8.492522183409303\n"
     ]
    }
   ],
   "source": [
    "# change root path inside the script\n",
    "%cd /workdir/SW/RotationDetection/dataloader/dataset/UFRGS_CELL\n",
    "!python convert2jpg.py /workdir/{DATASET}/02/images .tif 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/SW/RotationDetection/dataloader/dataset/UFRGS_CELL\n",
      "class_list 1\n",
      "find image 150\n",
      "find label 150\n",
      "100%|█████████████████████████████████████████| 150/150 [02:33<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# change train path inside the script\n",
    "%cd /workdir/SW/RotationDetection/dataloader/dataset/UFRGS_CELL\n",
    "!python data_crop.py /workdir/{DATASET}/02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change test path inside the script\n",
    "%cd /workdir/msc/RotationDetection/dataloader/dataset/UFRGS_CELL\n",
    "!python txt2xml.py \\\n",
    "'/workdir/msc/datasets/Fluo-N2DH-SIM+/01/annotations/dota_format' \\\n",
    "'/workdir/msc/datasets/Fluo-N2DH-SIM+/01/annotations/xml_rotdet' \\\n",
    "'/workdir/msc/datasets/Fluo-N2DH-SIM+/01/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "os.makedirs(f'/workdir/{DATASET}/crop_all/images', exist_ok=True)\n",
    "os.makedirs(f'/workdir/{DATASET}/crop_all/labeltxt', exist_ok=True)\n",
    "\n",
    "path_images = glob(f'/workdir/{DATASET}/*/crop/images/*.png')\n",
    "path_labels = glob(f'/workdir/{DATASET}/*/crop/labeltxt/*.xml')\n",
    "\n",
    "for path in path_images:\n",
    "    src = path\n",
    "    name = os.path.split(path)[-1]\n",
    "    name = path.split('/')[3]+'_'+name\n",
    "    \n",
    "    dst = os.path.join('/workdir',DATASET,'crop_all','images',name)\n",
    "    \n",
    "    os.rename(src, dst)\n",
    "    \n",
    "for path in path_labels:\n",
    "    src = path\n",
    "    name = os.path.split(path)[-1]\n",
    "    name = path.split('/')[3]+'_'+name\n",
    "    \n",
    "    dst = os.path.join('/workdir',DATASET,'crop_all','labeltxt',name)\n",
    "    \n",
    "    os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/SW/RotationDetection/dataloader/dataset\n",
      "/workdir/SW/RotationDetection\n",
      "WARNING:tensorflow:From convert_data_to_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "100%|██████████████████████████████████████| 2985/2985 [00:26<00:00, 111.07it/s]\n",
      "\n",
      "Conversion is complete!\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/SW/RotationDetection/dataloader/dataset/\n",
    "!python convert_data_to_tfrecord.py --VOC_dir=/workdir/{DATASET}/crop_all \\\n",
    "                                    --xml_dir='labeltxt' \\\n",
    "                                    --image_dir='images' \\\n",
    "                                    --save_name='train'  \\\n",
    "                                    --img_format='.png'  \\\n",
    "                                    --save_dir=/workdir \\\n",
    "                                    --dataset='UFRGS_CELL_1class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r /workdir/msc/RotationDetection/output/**/*Fluo-N2DH-SIM+*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/SW/RotationDetection/tools/r2cnn\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "/workdir/SW/RotationDetection\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/mobilenet/mobilenet.py:357: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:139: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:219: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:33: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:111: The name tf.train.piecewise_constant is deprecated. Please use tf.compat.v1.train.piecewise_constant instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:35: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:37: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "tfrecord path is --> /workdir/UFRGS_CELL_1class_train*\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:115: The name tf.train.match_filenames_once is deprecated. Please use tf.io.match_filenames_once instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:117: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:26: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:29: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:32: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:223: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:209: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:42: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:128: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From train.py:80: The name tf.no_regularizer is deprecated. Please use tf.compat.v1.no_regularizer instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:83: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:83: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/r2cnn/build_whole_network.py:103: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/two_stage_base_network.py:138: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/two_stage_base_network.py:151: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/r2cnn/build_whole_network.py:111: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/r2cnn/build_whole_network.py:111: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/two_stage_base_network.py:245: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/roi_extractors/roi_extractors.py:42: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From train.py:145: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:178: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:182: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "model restore from pretrained mode, path is : /workdir/SW/RotationDetection/dataloader/pretrained_weights/resnet50_v1d.ckpt\n",
      "var_in_graph:  resnet50_v1d/C1/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C1/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C1/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/shortcut/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/shortcut/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_0/shortcut/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_1/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C2/bottleneck_2/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/shortcut/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/shortcut/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_0/shortcut/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_1/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_2/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C3/bottleneck_3/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/shortcut/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/shortcut/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_0/shortcut/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_1/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_2/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_3/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_4/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C4/bottleneck_5/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/shortcut/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/shortcut/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_0/shortcut/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_1/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv0/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv0/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv0/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv1/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv1/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv1/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv2/weights:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv2/weights\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/gamma:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/gamma\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/beta:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/beta\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/moving_mean:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/moving_mean\n",
      "____________________________________________________________\n",
      "var_in_graph:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/moving_variance:0\n",
      "var_in_ckpt:  resnet50_v1d/C5/bottleneck_2/conv2/BatchNorm/moving_variance\n",
      "____________________________________________________________\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/two_stage_base_network.py:226: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "********************************************************************************\n",
      "restore from pretrained_weighs in IMAGE_NET\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:188: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:189: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:192: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:195: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2022-08-21 20:34:39.073851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-08-21 20:34:39.095049: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz\n",
      "2022-08-21 20:34:39.095528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x52da4d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-21 20:34:39.095558: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-08-21 20:34:39.097140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-21 20:34:39.213164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-21 20:34:39.213762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8c8e0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-21 20:34:39.213779: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-08-21 20:34:39.213999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-21 20:34:39.214540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-08-21 20:34:39.214612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-08-21 20:34:39.215838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-08-21 20:34:39.216832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-08-21 20:34:39.217112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-08-21 20:34:39.218418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-08-21 20:34:39.219476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-08-21 20:34:39.222506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-21 20:34:39.222666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-21 20:34:39.223286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-21 20:34:39.223737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-08-21 20:34:39.223797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-08-21 20:34:39.225551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-21 20:34:39.225564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-08-21 20:34:39.225569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-08-21 20:34:39.225696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-21 20:34:39.226169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-21 20:34:39.226704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10253 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:200: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:204: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "restore model\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:30: The name tf.profiler.profile is deprecated. Please use tf.compat.v1.profiler.profile instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:30: The name tf.profiler.ProfileOptionBuilder is deprecated. Please use tf.compat.v1.profiler.ProfileOptionBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "613 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/595.61m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_64 (12.85m/38.54m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_64/mul (12.85m/12.85m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_64/sub_1 (12.85m/12.85m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_64/sub (1/1 flops)\n",
      "  tower_0/Fast-RCNN/build_fc_layers/fc1/kernel/Regularizer/l2_regularizer (1/38.54m flops)\n",
      "    tower_0/Fast-RCNN/build_fc_layers/fc1/kernel/Regularizer/l2_regularizer/L2Loss (38.54m/38.54m flops)\n",
      "  Fast-RCNN/build_fc_layers/fc1/weights/Initializer/random_uniform (12.85m/25.69m flops)\n",
      "    Fast-RCNN/build_fc_layers/fc1/weights/Initializer/random_uniform/mul (12.85m/12.85m flops)\n",
      "    Fast-RCNN/build_fc_layers/fc1/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_64/truediv (12.85m/12.85m flops)\n",
      "  tower_0/gradients/AddN_6 (12.85m/12.85m flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/build_fc_layers/fc1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (12.85m/12.85m flops)\n",
      "  tower_0/clip_by_norm_64/mul_1 (12.85m/12.85m flops)\n",
      "  tower_0/clip_by_norm_64/mul (12.85m/12.85m flops)\n",
      "  tower_0/clip_by_norm_64/Sum (12.85m/12.85m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_37 (2.36m/7.08m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_37/mul (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_37/sub_1 (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_37/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_40 (2.36m/7.08m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_40/mul (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_40/sub_1 (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_40/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_33 (2.36m/7.08m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_33/mul (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_33/sub_1 (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_33/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/7.08m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (7.08m/7.08m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/7.08m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (7.08m/7.08m flops)\n",
      "  tower_0/gradients/AddN_20 (7.08m/7.08m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/7.08m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (7.08m/7.08m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_35 (2.10m/6.29m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_35/mul (2.10m/2.10m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_35/sub_1 (2.10m/2.10m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_35/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/6.29m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (6.29m/6.29m flops)\n",
      "  resnet50_v1d/C5/bottleneck_2/conv1/weights/Initializer/truncated_normal (2.36m/4.72m flops)\n",
      "    resnet50_v1d/C5/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/conv1/weights/Initializer/truncated_normal (2.36m/4.72m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_1/conv1/weights/Initializer/truncated_normal (2.36m/4.72m flops)\n",
      "    resnet50_v1d/C5/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/shortcut/weights/Initializer/truncated_normal (2.10m/4.19m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (2.10m/2.10m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_58 (1.18m/3.54m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_58/mul (1.18m/1.18m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_58/sub_1 (1.18m/1.18m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_58/sub (1/1 flops)\n",
      "  build_rpn/rpn_conv/3x3/weights/Regularizer/l2_regularizer (1/3.54m flops)\n",
      "    build_rpn/rpn_conv/3x3/weights/Regularizer/l2_regularizer/L2Loss (3.54m/3.54m flops)\n",
      "  tower_0/build_rpn/rpn_conv/3x3/kernel/Regularizer/l2_regularizer (1/3.54m flops)\n",
      "    tower_0/build_rpn/rpn_conv/3x3/kernel/Regularizer/l2_regularizer/L2Loss (3.54m/3.54m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_66 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_66/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_66/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_66/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_41 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_41/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_41/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_41/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_39 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_39/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_39/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_39/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_38 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_38/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_38/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_38/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_34 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_34/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_34/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_34/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_36 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_36/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_36/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_36/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/Fast-RCNN/build_fc_layers/fc2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/Fast-RCNN/build_fc_layers/fc2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/clip_by_norm_40/truediv (2.36m/2.36m flops)\n",
      "  tower_0/gradients/AddN_43 (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_33/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_33/mul_1 (2.36m/2.36m flops)\n",
      "  tower_0/gradients/AddN_38 (2.36m/2.36m flops)\n",
      "  tower_0/gradients/AddN_34 (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_33/truediv (2.36m/2.36m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_40/mul_1 (2.36m/2.36m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_40/mul (2.36m/2.36m flops)\n",
      "  build_rpn/rpn_conv/3x3/weights/Initializer/random_normal (1.18m/2.36m flops)\n",
      "    build_rpn/rpn_conv/3x3/weights/Initializer/random_normal/mul (1.18m/1.18m flops)\n",
      "  tower_0/clip_by_norm_37/truediv (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_37/mul_1 (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_37/mul (2.36m/2.36m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_40/Sum (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_37/Sum (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_33/Sum (2.36m/2.36m flops)\n",
      "  Fast-RCNN/build_fc_layers/fc2/weights/Initializer/random_uniform (1.05m/2.10m flops)\n",
      "    Fast-RCNN/build_fc_layers/fc2/weights/Initializer/random_uniform/mul (1.05m/1.05m flops)\n",
      "    Fast-RCNN/build_fc_layers/fc2/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  resnet50_v1d/C5/bottleneck_2/conv2/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_35/truediv (2.10m/2.10m flops)\n",
      "  tower_0/clip_by_norm_35/mul_1 (2.10m/2.10m flops)\n",
      "  tower_0/clip_by_norm_35/mul (2.10m/2.10m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.10m/2.10m flops)\n",
      "  tower_0/gradients/AddN_42 (2.10m/2.10m flops)\n",
      "  resnet50_v1d/C5/bottleneck_1/conv0/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_2/conv0/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_1/conv2/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/conv2/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_35/Sum (2.10m/2.10m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_54 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_54/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_54/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_54/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_30 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_30/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_30/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_30/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_56 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_56/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_56/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_56/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_27 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_27/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_27/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_27/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_24 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_24/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_24/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_24/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_52 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_52/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_52/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_52/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_21 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_21/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_21/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_21/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_18 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_18/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_18/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_18/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_14 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_14/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_14/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_14/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_50 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_50/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_50/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_50/sub (1/1 flops)\n",
      "  tower_0/build_pyramid/fuse_P2/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P2/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_42 (524.29k/1.57m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_42/mul (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_42/sub_1 (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_42/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_16 (524.29k/1.57m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_16/mul (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_16/sub_1 (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_16/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_32 (524.29k/1.57m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_32/mul (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_32/sub_1 (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_32/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/1.57m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (1.57m/1.57m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/1.57m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (1.57m/1.57m flops)\n",
      "  tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer (1/1.57m flops)\n",
      "    tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer/L2Loss (1.57m/1.57m flops)\n",
      "  build_pyramid/fuse_P2/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P2/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P2/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/fuse_P3/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P3/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P3/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/fuse_P4/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P4/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P4/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/fuse_P5/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P5/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P5/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  resnet50_v1d/C4/bottleneck_2/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_3/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_3/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_conv/3x3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.18m/1.18m flops)\n",
      "  resnet50_v1d/C4/bottleneck_4/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_4/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_1/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/build_rpn/rpn_conv/3x3/weights/Regularizer/l2_regularizer/L2Loss_grad/mul (1.18m/1.18m flops)\n",
      "  resnet50_v1d/C4/bottleneck_5/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_5/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_58/mul (1.18m/1.18m flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_58/truediv (1.18m/1.18m flops)\n",
      "  tower_0/clip_by_norm_58/mul_1 (1.18m/1.18m flops)\n",
      "  tower_0/clip_by_norm_58/Sum (1.18m/1.18m flops)\n",
      "  build_pyramid/build_P5/weights/Initializer/random_uniform (524.29k/1.05m flops)\n",
      "    build_pyramid/build_P5/weights/Initializer/random_uniform/mul (524.29k/524.29k flops)\n",
      "    build_pyramid/build_P5/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_41/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/conv0/weights/Initializer/truncated_normal (524.29k/1.05m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_41/truediv (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_41/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_36/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_36/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_36/truediv (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_34/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_39/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_34/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/shortcut/weights/Initializer/truncated_normal (524.29k/1.05m flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_34/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_38/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_38/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_38/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_39/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_39/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_33 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_36 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_37 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_40 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_41 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_5 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_66/truediv (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/build_fc_layers/fc2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_66/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_66/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_36/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_66/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_38/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_34/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_39/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_41/Sum (1.05m/1.05m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_22 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_22/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_22/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_22/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_20 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_20/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_20/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_20/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_19 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_19/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_19/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_19/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_23 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_23/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_23/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_23/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_25 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_25/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_25/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_25/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_26 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_26/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_26/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_26/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_17 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_17/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_17/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_17/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_15 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_15/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_15/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_15/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_28 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_28/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_28/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_28/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_29 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_29/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_29/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_29/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_44 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_44/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_44/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_44/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_31 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_31/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_31/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_31/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/gradients/AddN_63 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_59 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_55 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_51 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_14/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_47 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_14/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_68 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_30/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_54/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_54/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_30/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_30/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_52/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_52/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_18/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_52/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_25 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_50/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_50/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_50/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_27/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_18/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_21/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_14/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_24 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_23 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_27/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_22 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_21/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_21/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_27/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_18/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_56/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_56/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_56/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_54/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_14/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_30/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_27/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_21/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_18/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_50/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_52/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_54/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_56/Sum (589.82k/589.82k flops)\n",
      "  build_pyramid/build_P4/reduce_dim_P4/weights/Initializer/random_uniform (262.14k/524.29k flops)\n",
      "    build_pyramid/build_P4/reduce_dim_P4/weights/Initializer/random_uniform/mul (262.14k/262.14k flops)\n",
      "    build_pyramid/build_P4/reduce_dim_P4/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_16/truediv (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_16/mul_1 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_16/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/mul (524.29k/524.29k flops)\n",
      "  resnet50_v1d/C4/bottleneck_1/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_67 (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_45 (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_32 (524.29k/524.29k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/truediv (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/mul_1 (524.29k/524.29k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (524.29k/524.29k flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_1/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_2/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_2/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_3/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_3/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_3/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_3/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_4/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_4/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_4/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_4/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_5/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_5/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_5/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_5/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_32/truediv (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_32/mul_1 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_32/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_32/Sum (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/Sum (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_16/Sum (524.29k/524.29k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_1 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_1/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_1/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_1/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_8 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_8/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_8/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_8/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_5 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_5/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_5/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_5/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_11 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_11/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_11/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_11/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_46 (131.07k/393.22k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_46/mul (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_46/sub_1 (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_46/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_3 (131.07k/393.22k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_3/mul (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_3/sub_1 (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_3/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_13 (131.07k/393.22k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_13/mul (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_13/sub_1 (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_13/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/393.22k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (393.21k/393.21k flops)\n",
      "  tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer (1/393.22k flops)\n",
      "    tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer/L2Loss (393.21k/393.21k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/393.22k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (393.21k/393.21k flops)\n",
      "  resnet50_v1d/C3/bottleneck_2/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  resnet50_v1d/C3/bottleneck_1/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  resnet50_v1d/C3/bottleneck_3/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_3/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  build_pyramid/build_P3/reduce_dim_P3/weights/Initializer/random_uniform (131.07k/262.14k flops)\n",
      "    build_pyramid/build_P3/reduce_dim_P3/weights/Initializer/random_uniform/mul (131.07k/131.07k flops)\n",
      "    build_pyramid/build_P3/reduce_dim_P3/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_25/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_26/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_28/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_28/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_28/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_49 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_46 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_26/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_26/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_23/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_23/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_22/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_23/truediv (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_31 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_44/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/shortcut/weights/Initializer/truncated_normal (131.07k/262.14k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_44/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_44/truediv (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/conv0/weights/Initializer/truncated_normal (131.07k/262.14k flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_31/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_31/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_31/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_17/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_17/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_15/truediv (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_61 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_58 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_15/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_62 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_65 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_20/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_20/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_20/truediv (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_57 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_66 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_15/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_54 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_19/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_17/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_19/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_19/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_22/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_53 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_50 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_22/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_17/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_19/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_31/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_28/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_22/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_44/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_15/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_23/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_26/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_20/Sum (262.14k/262.14k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_9 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_9/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_9/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_9/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_12 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_12/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_12/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_12/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_4 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_4/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_4/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_4/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_2 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_2/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_2/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_2/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_7 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_7/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_7/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_7/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_48 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_48/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_48/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_48/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_10 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_10/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_10/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_10/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_6 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_6/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_6/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_6/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/build_pyramid/build_P2/reduce_dim_P2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/build_pyramid/build_P2/reduce_dim_P2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/clip_by_norm_5/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_5/truediv (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_5/mul (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_85 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_1/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_80 (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_76 (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_72 (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_8/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_8/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_1/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_1/truediv (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/truediv (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/mul (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_8/truediv (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/Sum (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_8/Sum (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_5/Sum (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_1/Sum (147.46k/147.46k flops)\n",
      "  build_pyramid/build_P2/reduce_dim_P2/weights/Initializer/random_uniform (65.54k/131.07k flops)\n",
      "    build_pyramid/build_P2/reduce_dim_P2/weights/Initializer/random_uniform/mul (65.54k/65.54k flops)\n",
      "    build_pyramid/build_P2/reduce_dim_P2/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  resnet50_v1d/C3/bottleneck_2/conv0/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_29 (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_2/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  resnet50_v1d/C3/bottleneck_3/conv0/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_3/conv0/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  resnet50_v1d/C3/bottleneck_1/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  resnet50_v1d/C3/bottleneck_1/conv0/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_46/mul (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_13/truediv (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_13/mul_1 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_13/mul (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_3/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_3/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_46/mul_1 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_46/truediv (131.07k/131.07k flops)\n",
      "  tower_0/gradients/AddN_70 (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_3/mul (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_3/mul_1 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_3/truediv (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (131.07k/131.07k flops)\n",
      "  tower_0/gradients/AddN_84 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_13/Sum (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_46/Sum (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_3/Sum (131.07k/131.07k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg (32.77k/98.31k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg/mul (32.77k/32.77k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg/sub_1 (32.77k/32.77k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/98.30k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (98.30k/98.30k flops)\n",
      "  tower_0/gradients/AddN_15 (86.02k/86.02k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/conv1/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
      "  resnet50_v1d/C2/bottleneck_2/conv1/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
      "    resnet50_v1d/C2/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
      "  resnet50_v1d/C2/bottleneck_1/conv1/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
      "    resnet50_v1d/C2/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
      "  tower_0/gradients/AddN_83 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_2/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_9/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_9/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_2/mul (65.54k/65.54k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/conv0/weights/Initializer/truncated_normal (32.77k/65.54k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (32.77k/32.77k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_27 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_12/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_12/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_74 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_82 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_12/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_2/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_71 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_48/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_48/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_79 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_78 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_48/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_75 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_7/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_6/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_6/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P2/reduce_dim_P2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_4/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_4/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_4/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_7/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_7/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_6/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_10/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_10/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_10/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_9/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_9/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_2/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_12/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_6/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_48/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_4/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_7/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_10/Sum (65.53k/65.53k flops)\n",
      "  tower_0/resnet50_v1d/C1/conv2/kernel/Regularizer/l2_regularizer (1/55.30k flops)\n",
      "    tower_0/resnet50_v1d/C1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (55.30k/55.30k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_62 (14.34k/43.01k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_62/mul (14.34k/14.34k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_62/sub_1 (14.34k/14.34k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_62/sub (1/1 flops)\n",
      "  tower_0/gradients/AddN_8 (43.01k/43.01k flops)\n",
      "  build_rpn/rpn_bbox_pred/weights/Regularizer/l2_regularizer (1/43.01k flops)\n",
      "    build_rpn/rpn_bbox_pred/weights/Regularizer/l2_regularizer/L2Loss (43.01k/43.01k flops)\n",
      "  tower_0/build_rpn/rpn_bbox_pred/kernel/Regularizer/l2_regularizer (1/43.01k flops)\n",
      "    tower_0/build_rpn/rpn_bbox_pred/kernel/Regularizer/l2_regularizer/L2Loss (43.01k/43.01k flops)\n",
      "  resnet50_v1d/C1/conv2/weights/Initializer/truncated_normal (18.43k/36.86k flops)\n",
      "    resnet50_v1d/C1/conv2/weights/Initializer/truncated_normal/mul (18.43k/18.43k flops)\n",
      "  resnet50_v1d/C2/bottleneck_2/conv2/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_1/conv0/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm/mul_1 (32.77k/32.77k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (32.77k/32.77k flops)\n",
      "  resnet50_v1d/C2/bottleneck_1/conv2/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm/truediv (32.77k/32.77k flops)\n",
      "  tower_0/clip_by_norm/mul (32.77k/32.77k flops)\n",
      "  resnet50_v1d/C2/bottleneck_2/conv0/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/conv2/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/shortcut/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_86 (32.77k/32.77k flops)\n",
      "  tower_0/clip_by_norm/Sum (32.77k/32.77k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_70 (10.24k/30.72k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_70/mul (10.24k/10.24k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_70/sub_1 (10.24k/10.24k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_70/sub (1/1 flops)\n",
      "  tower_0/Fast-RCNN/reg_fc/kernel/Regularizer/l2_regularizer (1/30.72k flops)\n",
      "    tower_0/Fast-RCNN/reg_fc/kernel/Regularizer/l2_regularizer/L2Loss (30.72k/30.72k flops)\n",
      "  build_rpn/rpn_bbox_pred/weights/Initializer/random_normal (14.34k/28.67k flops)\n",
      "    build_rpn/rpn_bbox_pred/weights/Initializer/random_normal/mul (14.34k/14.34k flops)\n",
      "  tower_0/resnet50_v1d/C1/conv1/kernel/Regularizer/l2_regularizer (1/27.65k flops)\n",
      "    tower_0/resnet50_v1d/C1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (27.65k/27.65k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_60 (7.17k/21.50k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_60/mul (7.17k/7.17k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_60/sub_1 (7.17k/7.17k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_60/sub (1/1 flops)\n",
      "  build_rpn/rpn_cls_score/weights/Regularizer/l2_regularizer (1/21.50k flops)\n",
      "    build_rpn/rpn_cls_score/weights/Regularizer/l2_regularizer/L2Loss (21.50k/21.50k flops)\n",
      "  tower_0/build_rpn/rpn_cls_score/kernel/Regularizer/l2_regularizer (1/21.50k flops)\n",
      "    tower_0/build_rpn/rpn_cls_score/kernel/Regularizer/l2_regularizer/L2Loss (21.50k/21.50k flops)\n",
      "  Fast-RCNN/reg_fc/weights/Initializer/random_normal (10.24k/20.48k flops)\n",
      "    Fast-RCNN/reg_fc/weights/Initializer/random_normal/mul (10.24k/10.24k flops)\n",
      "  resnet50_v1d/C1/conv1/weights/Initializer/truncated_normal (9.22k/18.43k flops)\n",
      "    resnet50_v1d/C1/conv1/weights/Initializer/truncated_normal/mul (9.22k/9.22k flops)\n",
      "  tower_0/clip_by_norm_62/mul (14.34k/14.34k flops)\n",
      "  tower_0/clip_by_norm_62/truediv (14.34k/14.34k flops)\n",
      "  tower_0/clip_by_norm_62/mul_1 (14.34k/14.34k flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_bbox_pred/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (14.34k/14.34k flops)\n",
      "  tower_0/gradients/build_rpn/rpn_bbox_pred/weights/Regularizer/l2_regularizer/L2Loss_grad/mul (14.34k/14.34k flops)\n",
      "  build_rpn/rpn_cls_score/weights/Initializer/random_normal (7.17k/14.34k flops)\n",
      "    build_rpn/rpn_cls_score/weights/Initializer/random_normal/mul (7.17k/7.17k flops)\n",
      "  tower_0/clip_by_norm_62/Sum (14.34k/14.34k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/12.29k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (12.29k/12.29k flops)\n",
      "  tower_0/clip_by_norm_70/truediv (10.24k/10.24k flops)\n",
      "  tower_0/clip_by_norm_70/mul_1 (10.24k/10.24k flops)\n",
      "  tower_0/clip_by_norm_70/mul (10.24k/10.24k flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/reg_fc/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (10.24k/10.24k flops)\n",
      "  tower_0/gradients/AddN_4 (10.24k/10.24k flops)\n",
      "  tower_0/clip_by_norm_70/Sum (10.24k/10.24k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/conv0/weights/Initializer/truncated_normal (4.10k/8.19k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (4.10k/4.10k flops)\n",
      "  tower_0/gradients/build_rpn/rpn_cls_score/weights/Regularizer/l2_regularizer/L2Loss_grad/mul (7.17k/7.17k flops)\n",
      "  tower_0/clip_by_norm_60/truediv (7.17k/7.17k flops)\n",
      "  tower_0/clip_by_norm_60/mul_1 (7.17k/7.17k flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_cls_score/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (7.17k/7.17k flops)\n",
      "  tower_0/clip_by_norm_60/mul (7.17k/7.17k flops)\n",
      "  tower_0/clip_by_norm_60/Sum (7.17k/7.17k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_68 (2.05k/6.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_68/mul (2.05k/2.05k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_68/sub_1 (2.05k/2.05k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_68/sub (1/1 flops)\n",
      "  tower_0/Fast-RCNN/cls_fc/kernel/Regularizer/l2_regularizer (1/6.14k flops)\n",
      "    tower_0/Fast-RCNN/cls_fc/kernel/Regularizer/l2_regularizer/L2Loss (6.14k/6.14k flops)\n",
      "  Fast-RCNN/cls_fc/weights/Initializer/random_normal (2.05k/4.10k flops)\n",
      "    Fast-RCNN/cls_fc/weights/Initializer/random_normal/mul (2.05k/2.05k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_67 (1.02k/3.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_67/mul (1.02k/1.02k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_67/sub_1 (1.02k/1.02k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_67/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_65 (1.02k/3.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_65/mul (1.02k/1.02k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_65/sub_1 (1.02k/1.02k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_65/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C1/conv0/kernel/Regularizer/l2_regularizer (1/2.59k flops)\n",
      "    tower_0/resnet50_v1d/C1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (2.59k/2.59k flops)\n",
      "  tower_0/gradients/AddN_16 (2.56k/2.56k flops)\n",
      "  tower_0/clip_by_norm_68/mul (2.05k/2.05k flops)\n",
      "  tower_0/clip_by_norm_68/mul_1 (2.05k/2.05k flops)\n",
      "  tower_0/clip_by_norm_68/truediv (2.05k/2.05k flops)\n",
      "  tower_0/gradients/AddN (2.05k/2.05k flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/cls_fc/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.05k/2.05k flops)\n",
      "  tower_0/clip_by_norm_68/Sum (2.05k/2.05k flops)\n",
      "  resnet50_v1d/C1/conv0/weights/Initializer/truncated_normal (864/1.73k flops)\n",
      "    resnet50_v1d/C1/conv0/weights/Initializer/truncated_normal/mul (864/864 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_59 (512/1.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_59/mul (512/512 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_59/sub_1 (512/512 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_59/sub (1/1 flops)\n",
      "  build_rpn/rpn_conv/3x3/biases/Regularizer/l2_regularizer (1/1.54k flops)\n",
      "    build_rpn/rpn_conv/3x3/biases/Regularizer/l2_regularizer/L2Loss (1.53k/1.53k flops)\n",
      "  Gradient_Mult/Mul_12 (1.02k/1.02k flops)\n",
      "  Gradient_Mult/Mul_11 (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_65/mul (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_65/truediv (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_67/mul (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_67/mul_1 (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_67/truediv (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_65/mul_1 (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_67/Sum (1.02k/1.02k flops)\n",
      "  tower_0/clip_by_norm_65/Sum (1.02k/1.02k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_45 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_45/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_45/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_45/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_47 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_47/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_47/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_47/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_49 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_49/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_49/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_49/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_51 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_51/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_51/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_51/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_53 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_53/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_53/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_53/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_55 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_55/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_55/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_55/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_57 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_57/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_57/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_57/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_43 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_43/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_43/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_43/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_59/mul_1 (512/512 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_conv/3x3/biases/Regularizer/l2_regularizer/L2Loss_grad/mul (512/512 flops)\n",
      "  Gradient_Mult/Mul_8 (512/512 flops)\n",
      "  tower_0/clip_by_norm_59/mul (512/512 flops)\n",
      "  tower_0/clip_by_norm_59/truediv (512/512 flops)\n",
      "  tower_0/clip_by_norm_59/Sum (511/511 flops)\n",
      "  Gradient_Mult/Mul_2 (256/256 flops)\n",
      "  tower_0/clip_by_norm_45/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_51/mul_1 (256/256 flops)\n",
      "  Gradient_Mult/Mul_1 (256/256 flops)\n",
      "  Gradient_Mult/Mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_49/mul (256/256 flops)\n",
      "  Gradient_Mult/Mul_3 (256/256 flops)\n",
      "  tower_0/clip_by_norm_47/truediv (256/256 flops)\n",
      "  Gradient_Mult/Mul_6 (256/256 flops)\n",
      "  Gradient_Mult/Mul_7 (256/256 flops)\n",
      "  tower_0/clip_by_norm_45/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_51/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_45/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_51/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_57/truediv (256/256 flops)\n",
      "  Gradient_Mult/Mul_5 (256/256 flops)\n",
      "  tower_0/clip_by_norm_47/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_47/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_43/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_49/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_57/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_57/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_43/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_43/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_49/mul_1 (256/256 flops)\n",
      "  Gradient_Mult/Mul_4 (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_45/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_47/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_43/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_53/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_49/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_57/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_51/Sum (255/255 flops)\n",
      "  tower_0/gradients/AddN_9 (140/140 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_63 (28/85 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_63/mul (28/28 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_63/sub_1 (28/28 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_63/sub (1/1 flops)\n",
      "  build_rpn/rpn_bbox_pred/biases/Regularizer/l2_regularizer (1/84 flops)\n",
      "    build_rpn/rpn_bbox_pred/biases/Regularizer/l2_regularizer/L2Loss (83/83 flops)\n",
      "  tower_0/AddN (75/75 flops)\n",
      "  tower_0/gradients/AddN_7 (70/70 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_61 (14/43 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_61/mul (14/14 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_61/sub_1 (14/14 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_61/sub (1/1 flops)\n",
      "  build_rpn/rpn_cls_score/biases/Regularizer/l2_regularizer (1/42 flops)\n",
      "    build_rpn/rpn_cls_score/biases/Regularizer/l2_regularizer/L2Loss (41/41 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_71 (10/31 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_71/mul (10/10 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_71/sub_1 (10/10 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_71/sub (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_bbox_pred/biases/Regularizer/l2_regularizer/L2Loss_grad/mul (28/28 flops)\n",
      "  tower_0/clip_by_norm_63/mul (28/28 flops)\n",
      "  Gradient_Mult/Mul_10 (28/28 flops)\n",
      "  tower_0/clip_by_norm_63/truediv (28/28 flops)\n",
      "  tower_0/clip_by_norm_63/mul_1 (28/28 flops)\n",
      "  tower_0/clip_by_norm_63/Sum (27/27 flops)\n",
      "  tower_0/clip_by_norm_61/mul_1 (14/14 flops)\n",
      "  tower_0/clip_by_norm_61/mul (14/14 flops)\n",
      "  tower_0/clip_by_norm_61/truediv (14/14 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_cls_score/biases/Regularizer/l2_regularizer/L2Loss_grad/mul (14/14 flops)\n",
      "  Gradient_Mult/Mul_9 (14/14 flops)\n",
      "  tower_0/clip_by_norm_61/Sum (13/13 flops)\n",
      "  tower_0/clip_by_norm_71/truediv (10/10 flops)\n",
      "  tower_0/clip_by_norm_71/mul_1 (10/10 flops)\n",
      "  Gradient_Mult/Mul_14 (10/10 flops)\n",
      "  tower_0/clip_by_norm_71/mul (10/10 flops)\n",
      "  tower_0/clip_by_norm_71/Sum (9/9 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_69 (2/7 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_69/mul (2/2 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_69/sub_1 (2/2 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_69/sub (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/assert_positive/assert_less/Less (4/4 flops)\n",
      "  get_batch/cond_3/flip_up_down/assert_positive/assert_less/Less (3/3 flops)\n",
      "  get_batch/random_uniform_2 (1/3 flops)\n",
      "    get_batch/random_uniform_2/mul (1/1 flops)\n",
      "    get_batch/random_uniform_2/sub (1/1 flops)\n",
      "  get_batch/random_uniform_1 (1/3 flops)\n",
      "    get_batch/random_uniform_1/mul (1/1 flops)\n",
      "    get_batch/random_uniform_1/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/Sum_grad/Maximum (3/3 flops)\n",
      "  get_batch/random_uniform (1/3 flops)\n",
      "    get_batch/random_uniform/mul (1/1 flops)\n",
      "    get_batch/random_uniform/sub (1/1 flops)\n",
      "  cond/PiecewiseConstant/case/num_true_conds (3/3 flops)\n",
      "  get_batch/cond_2/flip_left_right/assert_positive/assert_less/Less (3/3 flops)\n",
      "  tower_0/clip_by_norm_69/mul (2/2 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/Sum_grad/Maximum (2/2 flops)\n",
      "  Gradient_Mult/Mul_13 (2/2 flops)\n",
      "  tower_0/clip_by_norm_69/mul_1 (2/2 flops)\n",
      "  tower_0/clip_by_norm_69/truediv (2/2 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/Sum_1_grad/Maximum (2/2 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/sample_RCNN_minibatch/ones_1/Less (1/1 flops)\n",
      "  tower_0/postprocess_fastrcnn/Greater (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_bbox_pred/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_bbox_pred/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/truediv_4 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_conv/3x3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/sample_RCNN_minibatch/ones/Less (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_conv/3x3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_cls_score/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_rpn/rpn_cls_score/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/truediv_1 (1/1 flops)\n",
      "  tower_0/truediv_3 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/truediv_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_4_grad/RealDiv_2 (1/1 flops)\n",
      "  tower_0/sample_anchors_minibatch/ones/Less (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_4_grad/Neg (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_4_grad/RealDiv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_4_grad/RealDiv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_4_grad/mul (1/1 flops)\n",
      "  tower_0/ones/Less (1/1 flops)\n",
      "  tower_0/ones_1/Less (1/1 flops)\n",
      "  tower_0/postprocess_FPN/avoid_unenough_boxes (1/1 flops)\n",
      "  tower_0/postprocess_FPN/clip_boxes_to_img_boundaries/sub (1/1 flops)\n",
      "  tower_0/postprocess_FPN/clip_boxes_to_img_boundaries/sub_1 (1/1 flops)\n",
      "  tower_0/postprocess_FPN/clip_boxes_to_img_boundaries/sub_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/truediv (1/1 flops)\n",
      "  tower_0/sample_anchors_minibatch/ones_1/Less (1/1 flops)\n",
      "  tower_0/postprocess_FPN/clip_boxes_to_img_boundaries/sub_3 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/clip_by_norm_23/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_3/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_29/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_29/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_28/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_28/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_27/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_27/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_26/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_26/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_25/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_25/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_24/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_24/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_23/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_3/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_22/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_22/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_21/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_21/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_20/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_20/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_2/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_2/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_19/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_19/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_18/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_18/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_17/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_17/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_36/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_42/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_42/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_41/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_41/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_40/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_40/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_4/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_4/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_39/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_39/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_38/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_38/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_37/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_37/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_16/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_36/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_35/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_35/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_34/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_34/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_33/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_33/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_32/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_32/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_31/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_31/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_30/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_30/Greater (1/1 flops)\n",
      "  get_batch/Less (1/1 flops)\n",
      "  sub_1 (1/1 flops)\n",
      "  sub (1/1 flops)\n",
      "  get_batch/input_producer/mul (1/1 flops)\n",
      "  get_batch/input_producer/Greater (1/1 flops)\n",
      "  get_batch/cond_3/flip_up_down/assert_greater_equal/GreaterEqual (1/1 flops)\n",
      "  get_batch/cond_2/flip_left_right/assert_greater_equal/GreaterEqual (1/1 flops)\n",
      "  get_batch/cond_1/mul_1 (1/1 flops)\n",
      "  get_batch/cond_1/mul (1/1 flops)\n",
      "  get_batch/cond_1/Less_1 (1/1 flops)\n",
      "  get_batch/cond_1/Less (1/1 flops)\n",
      "  get_batch/batch/mul (1/1 flops)\n",
      "  get_batch/Less_3 (1/1 flops)\n",
      "  get_batch/Less_2 (1/1 flops)\n",
      "  get_batch/Less_1 (1/1 flops)\n",
      "  tower_0/Fast-RCNN/rois_pooling/ROI_Warping_P2/zeros/Less (1/1 flops)\n",
      "  cond/truediv (1/1 flops)\n",
      "  cond/mul (1/1 flops)\n",
      "  cond/PiecewiseConstant/case/LessEqual (1/1 flops)\n",
      "  cond/PiecewiseConstant/LessEqual_2 (1/1 flops)\n",
      "  cond/PiecewiseConstant/LessEqual_1 (1/1 flops)\n",
      "  cond/PiecewiseConstant/LessEqual (1/1 flops)\n",
      "  cond/PiecewiseConstant/Greater_2 (1/1 flops)\n",
      "  cond/PiecewiseConstant/Greater_1 (1/1 flops)\n",
      "  cond/PiecewiseConstant/Greater (1/1 flops)\n",
      "  Momentum (1/1 flops)\n",
      "  LessEqual (1/1 flops)\n",
      "  ExponentialMovingAverage/truediv (1/1 flops)\n",
      "  ExponentialMovingAverage/Minimum (1/1 flops)\n",
      "  tower_0/clip_by_norm_1/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_16/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_15/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_15/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_14/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_14/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_13/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_13/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_12/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_12/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_11/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_11/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_10/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_10/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_1/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_43/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm/Greater (1/1 flops)\n",
      "  tower_0/build_loss/rpn_loss/truediv (1/1 flops)\n",
      "  tower_0/build_loss/rpn_loss/mul_4 (1/1 flops)\n",
      "  tower_0/build_loss/rpn_loss/mul_3 (1/1 flops)\n",
      "  tower_0/build_loss/rpn_loss/Maximum (1/1 flops)\n",
      "  tower_0/build_loss/FastRCNN_loss/truediv (1/1 flops)\n",
      "  tower_0/build_loss/FastRCNN_loss/mul_6 (1/1 flops)\n",
      "  tower_0/build_loss/FastRCNN_loss/mul_5 (1/1 flops)\n",
      "  tower_0/assign_levels/Log_1 (1/1 flops)\n",
      "  tower_0/Fast-RCNN/rois_pooling/ROI_Warping_P5/zeros/Less (1/1 flops)\n",
      "  tower_0/Fast-RCNN/rois_pooling/ROI_Warping_P4/zeros/Less (1/1 flops)\n",
      "  tower_0/Fast-RCNN/rois_pooling/ROI_Warping_P3/zeros/Less (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/assert_greater_equal/GreaterEqual (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/build_fc_layers/fc1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/build_fc_layers/fc1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_conv/3x3/weights/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_conv/3x3/weights/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_conv/3x3/biases/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_conv/3x3/biases/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_cls_score/weights/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_cls_score/weights/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_cls_score/biases/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_cls_score/biases/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_bbox_pred/weights/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_bbox_pred/weights/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_bbox_pred/biases/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/build_rpn/rpn_bbox_pred/biases/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/build_fc_layers/fc2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/Greater_1 (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/GreaterEqual_1 (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/GreaterEqual (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_9/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_9/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_8/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_8/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_71/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_71/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_70/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_70/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_7/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_7/Greater (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/truediv_grad/RealDiv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P2/reduce_dim_P2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/truediv_grad/mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/truediv_grad/RealDiv_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/truediv_grad/RealDiv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/truediv_grad/RealDiv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/truediv_grad/Neg (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/mul_4_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/mul_4_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/mul_3_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/mul_3_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/Pow_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/rpn_loss/Mean_grad/Maximum (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/truediv_grad/mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/truediv_grad/RealDiv_2 (1/1 flops)\n",
      "  tower_0/clip_by_norm_69/Sum (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/truediv_grad/RealDiv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/truediv_grad/Neg (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/mul_6_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/mul_6_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/mul_5_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/mul_5_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/Pow_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/FastRCNN_loss/Mean_grad/Maximum (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/reg_fc/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/reg_fc/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/cls_fc/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/cls_fc/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/Fast-RCNN/build_fc_layers/fc2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/clip_by_norm_5/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_56/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_55/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_55/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_54/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_54/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_53/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_53/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_52/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_52/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_51/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_51/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_50/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_50/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_5/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_56/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_49/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_49/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_48/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_48/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_47/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_47/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_46/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_46/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_45/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_45/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_44/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_44/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_43/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_62/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_69/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_69/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_68/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_68/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_67/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_67/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_66/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_66/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_65/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_65/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_64/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_64/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_63/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_63/Greater (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P2/reduce_dim_P2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/clip_by_norm_62/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_61/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_61/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_60/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_60/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_6/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_6/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_59/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_59/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_58/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_58/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_57/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_57/Greater (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "613 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/41.69m params)\n",
      "  Fast-RCNN (--/13.91m params)\n",
      "    Fast-RCNN/build_fc_layers (--/13.90m params)\n",
      "      Fast-RCNN/build_fc_layers/fc1 (--/12.85m params)\n",
      "        Fast-RCNN/build_fc_layers/fc1/biases (1024, 1.02k/1.02k params)\n",
      "        Fast-RCNN/build_fc_layers/fc1/weights (12544x1024, 12.85m/12.85m params)\n",
      "      Fast-RCNN/build_fc_layers/fc2 (--/1.05m params)\n",
      "        Fast-RCNN/build_fc_layers/fc2/biases (1024, 1.02k/1.02k params)\n",
      "        Fast-RCNN/build_fc_layers/fc2/weights (1024x1024, 1.05m/1.05m params)\n",
      "    Fast-RCNN/cls_fc (--/2.05k params)\n",
      "      Fast-RCNN/cls_fc/biases (2, 2/2 params)\n",
      "      Fast-RCNN/cls_fc/weights (1024x2, 2.05k/2.05k params)\n",
      "    Fast-RCNN/reg_fc (--/10.25k params)\n",
      "      Fast-RCNN/reg_fc/biases (10, 10/10 params)\n",
      "      Fast-RCNN/reg_fc/weights (1024x10, 10.24k/10.24k params)\n",
      "  build_pyramid (--/3.34m params)\n",
      "    build_pyramid/build_P2 (--/65.79k params)\n",
      "      build_pyramid/build_P2/reduce_dim_P2 (--/65.79k params)\n",
      "        build_pyramid/build_P2/reduce_dim_P2/biases (256, 256/256 params)\n",
      "        build_pyramid/build_P2/reduce_dim_P2/weights (1x1x256x256, 65.54k/65.54k params)\n",
      "    build_pyramid/build_P3 (--/131.33k params)\n",
      "      build_pyramid/build_P3/reduce_dim_P3 (--/131.33k params)\n",
      "        build_pyramid/build_P3/reduce_dim_P3/biases (256, 256/256 params)\n",
      "        build_pyramid/build_P3/reduce_dim_P3/weights (1x1x512x256, 131.07k/131.07k params)\n",
      "    build_pyramid/build_P4 (--/262.40k params)\n",
      "      build_pyramid/build_P4/reduce_dim_P4 (--/262.40k params)\n",
      "        build_pyramid/build_P4/reduce_dim_P4/biases (256, 256/256 params)\n",
      "        build_pyramid/build_P4/reduce_dim_P4/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "    build_pyramid/build_P5 (--/524.54k params)\n",
      "      build_pyramid/build_P5/biases (256, 256/256 params)\n",
      "      build_pyramid/build_P5/weights (1x1x2048x256, 524.29k/524.29k params)\n",
      "    build_pyramid/fuse_P2 (--/590.08k params)\n",
      "      build_pyramid/fuse_P2/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/fuse_P3 (--/590.08k params)\n",
      "      build_pyramid/fuse_P3/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/fuse_P4 (--/590.08k params)\n",
      "      build_pyramid/fuse_P4/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P4/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/fuse_P5 (--/590.08k params)\n",
      "      build_pyramid/fuse_P5/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P5/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "  build_rpn (--/1.20m params)\n",
      "    build_rpn/rpn_bbox_pred (--/14.36k params)\n",
      "      build_rpn/rpn_bbox_pred/biases (28, 28/28 params)\n",
      "      build_rpn/rpn_bbox_pred/weights (1x1x512x28, 14.34k/14.34k params)\n",
      "    build_rpn/rpn_cls_score (--/7.18k params)\n",
      "      build_rpn/rpn_cls_score/biases (14, 14/14 params)\n",
      "      build_rpn/rpn_cls_score/weights (1x1x512x14, 7.17k/7.17k params)\n",
      "    build_rpn/rpn_conv (--/1.18m params)\n",
      "      build_rpn/rpn_conv/3x3 (--/1.18m params)\n",
      "        build_rpn/rpn_conv/3x3/biases (512, 512/512 params)\n",
      "        build_rpn/rpn_conv/3x3/weights (3x3x256x512, 1.18m/1.18m params)\n",
      "  resnet50_v1d (--/23.23m params)\n",
      "    resnet50_v1d/C3 (--/1.21m params)\n",
      "      resnet50_v1d/C3/bottleneck_0 (--/376.83k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/conv0 (--/32.77k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/conv0/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/shortcut (--/131.07k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      resnet50_v1d/C3/bottleneck_1 (--/278.53k params)\n",
      "        resnet50_v1d/C3/bottleneck_1/conv0 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_1/conv0/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_1/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_1/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_1/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_1/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "      resnet50_v1d/C3/bottleneck_2 (--/278.53k params)\n",
      "        resnet50_v1d/C3/bottleneck_2/conv0 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_2/conv0/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_2/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_2/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_2/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_2/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "      resnet50_v1d/C3/bottleneck_3 (--/278.53k params)\n",
      "        resnet50_v1d/C3/bottleneck_3/conv0 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_3/conv0/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_3/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_3/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_3/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_3/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "    resnet50_v1d/C4 (--/7.08m params)\n",
      "      resnet50_v1d/C4/bottleneck_0 (--/1.51m params)\n",
      "        resnet50_v1d/C4/bottleneck_0/conv0 (--/131.07k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/conv0/weights (1x1x512x256, 131.07k/131.07k params)\n",
      "        resnet50_v1d/C4/bottleneck_0/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_0/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_0/shortcut (--/524.29k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
      "      resnet50_v1d/C4/bottleneck_1 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_1/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_1/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_1/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_1/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_1/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_1/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_2 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_2/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_2/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_2/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_2/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_2/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_2/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_3 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_3/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_3/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_3/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_3/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_3/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_3/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_4 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_4/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_4/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_4/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_4/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_4/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_4/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_5 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_5/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_5/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_5/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_5/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_5/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_5/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "    resnet50_v1d/C5 (--/14.94m params)\n",
      "      resnet50_v1d/C5/bottleneck_0 (--/6.03m params)\n",
      "        resnet50_v1d/C5/bottleneck_0/conv0 (--/524.29k params)\n",
      "          resnet50_v1d/C5/bottleneck_0/conv0/weights (1x1x1024x512, 524.29k/524.29k params)\n",
      "        resnet50_v1d/C5/bottleneck_0/conv1 (--/2.36m params)\n",
      "          resnet50_v1d/C5/bottleneck_0/conv1/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "        resnet50_v1d/C5/bottleneck_0/conv2 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_0/conv2/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "        resnet50_v1d/C5/bottleneck_0/shortcut (--/2.10m params)\n",
      "          resnet50_v1d/C5/bottleneck_0/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
      "      resnet50_v1d/C5/bottleneck_1 (--/4.46m params)\n",
      "        resnet50_v1d/C5/bottleneck_1/conv0 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_1/conv0/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "        resnet50_v1d/C5/bottleneck_1/conv1 (--/2.36m params)\n",
      "          resnet50_v1d/C5/bottleneck_1/conv1/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "        resnet50_v1d/C5/bottleneck_1/conv2 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_1/conv2/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "      resnet50_v1d/C5/bottleneck_2 (--/4.46m params)\n",
      "        resnet50_v1d/C5/bottleneck_2/conv0 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_2/conv0/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "        resnet50_v1d/C5/bottleneck_2/conv1 (--/2.36m params)\n",
      "          resnet50_v1d/C5/bottleneck_2/conv1/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "        resnet50_v1d/C5/bottleneck_2/conv2 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_2/conv2/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPs: 595607523;    Trainable params: 41686582\n",
      "2022-08-21 20:34:48.379948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-08-21 20:34:48.701823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "************************************************************************\n",
      "2022-08-21 20:35:01: global_step:20  current_step:20\n",
      "speed: 2.794s, remaining training time: 01:04:56:14\n",
      "total_losses:2.080\n",
      "rpn_cls_loss:0.447\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:1.144\n",
      "fast_reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:10: global_step:40  current_step:40\n",
      "speed: 0.323s, remaining training time: 00:03:20:43\n",
      "total_losses:0.363\n",
      "rpn_cls_loss:0.069\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.175\n",
      "fast_reg_loss:0.107\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:17: global_step:60  current_step:60\n",
      "speed: 0.328s, remaining training time: 00:03:23:16\n",
      "total_losses:0.310\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.155\n",
      "fast_reg_loss:0.121\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:23: global_step:80  current_step:80\n",
      "speed: 0.336s, remaining training time: 00:03:28:22\n",
      "total_losses:0.307\n",
      "rpn_cls_loss:0.096\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.140\n",
      "fast_reg_loss:0.063\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:30: global_step:100  current_step:100\n",
      "speed: 0.322s, remaining training time: 00:03:19:50\n",
      "total_losses:0.438\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.247\n",
      "fast_reg_loss:0.153\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:37: global_step:120  current_step:120\n",
      "speed: 0.320s, remaining training time: 00:03:18:18\n",
      "total_losses:0.579\n",
      "rpn_cls_loss:0.038\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.251\n",
      "fast_reg_loss:0.275\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:43: global_step:140  current_step:140\n",
      "speed: 0.318s, remaining training time: 00:03:17:05\n",
      "total_losses:0.181\n",
      "rpn_cls_loss:0.010\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.108\n",
      "fast_reg_loss:0.059\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:50: global_step:160  current_step:160\n",
      "speed: 0.300s, remaining training time: 00:03:06:00\n",
      "total_losses:0.450\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.214\n",
      "fast_reg_loss:0.180\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:35:56: global_step:180  current_step:180\n",
      "speed: 0.325s, remaining training time: 00:03:21:13\n",
      "total_losses:0.637\n",
      "rpn_cls_loss:0.060\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.275\n",
      "fast_reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:10: global_step:220  current_step:220\n",
      "speed: 0.345s, remaining training time: 00:03:33:30\n",
      "total_losses:0.567\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.255\n",
      "fast_reg_loss:0.258\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:17: global_step:240  current_step:240\n",
      "speed: 0.362s, remaining training time: 00:03:43:21\n",
      "total_losses:1.080\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.441\n",
      "fast_reg_loss:0.604\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:24: global_step:260  current_step:260\n",
      "speed: 0.333s, remaining training time: 00:03:25:23\n",
      "total_losses:0.398\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.237\n",
      "fast_reg_loss:0.111\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:31: global_step:280  current_step:280\n",
      "speed: 0.374s, remaining training time: 00:03:51:02\n",
      "total_losses:0.902\n",
      "rpn_cls_loss:0.059\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.370\n",
      "fast_reg_loss:0.459\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:38: global_step:300  current_step:300\n",
      "speed: 0.336s, remaining training time: 00:03:27:25\n",
      "total_losses:0.493\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.259\n",
      "fast_reg_loss:0.172\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:45: global_step:320  current_step:320\n",
      "speed: 0.304s, remaining training time: 00:03:07:08\n",
      "total_losses:0.658\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.342\n",
      "fast_reg_loss:0.257\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:52: global_step:340  current_step:340\n",
      "speed: 0.351s, remaining training time: 00:03:36:24\n",
      "total_losses:1.303\n",
      "rpn_cls_loss:0.059\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.527\n",
      "fast_reg_loss:0.702\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:36:58: global_step:360  current_step:360\n",
      "speed: 0.306s, remaining training time: 00:03:08:18\n",
      "total_losses:0.456\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.221\n",
      "fast_reg_loss:0.206\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:37:06: global_step:380  current_step:380\n",
      "speed: 0.336s, remaining training time: 00:03:26:27\n",
      "total_losses:1.193\n",
      "rpn_cls_loss:0.082\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.408\n",
      "fast_reg_loss:0.688\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:19: global_step:420  current_step:420\n",
      "speed: 0.367s, remaining training time: 00:03:45:30\n",
      "total_losses:1.068\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.422\n",
      "fast_reg_loss:0.583\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:26: global_step:440  current_step:440\n",
      "speed: 0.310s, remaining training time: 00:03:10:18\n",
      "total_losses:0.525\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.233\n",
      "fast_reg_loss:0.251\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:33: global_step:460  current_step:460\n",
      "speed: 0.331s, remaining training time: 00:03:23:18\n",
      "total_losses:1.312\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.516\n",
      "fast_reg_loss:0.741\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:39: global_step:480  current_step:480\n",
      "speed: 0.333s, remaining training time: 00:03:24:27\n",
      "total_losses:0.795\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.317\n",
      "fast_reg_loss:0.426\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:46: global_step:500  current_step:500\n",
      "speed: 0.336s, remaining training time: 00:03:25:57\n",
      "total_losses:0.682\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.300\n",
      "fast_reg_loss:0.319\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:53: global_step:520  current_step:520\n",
      "speed: 0.326s, remaining training time: 00:03:19:47\n",
      "total_losses:0.426\n",
      "rpn_cls_loss:0.013\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.176\n",
      "fast_reg_loss:0.232\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:37:59: global_step:540  current_step:540\n",
      "speed: 0.328s, remaining training time: 00:03:21:01\n",
      "total_losses:1.123\n",
      "rpn_cls_loss:0.039\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.413\n",
      "fast_reg_loss:0.656\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:06: global_step:560  current_step:560\n",
      "speed: 0.322s, remaining training time: 00:03:16:59\n",
      "total_losses:1.002\n",
      "rpn_cls_loss:0.085\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.383\n",
      "fast_reg_loss:0.521\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:13: global_step:580  current_step:580\n",
      "speed: 0.347s, remaining training time: 00:03:32:16\n",
      "total_losses:0.950\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.323\n",
      "fast_reg_loss:0.585\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:26: global_step:620  current_step:620\n",
      "speed: 0.330s, remaining training time: 00:03:21:30\n",
      "total_losses:0.719\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.262\n",
      "fast_reg_loss:0.415\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:33: global_step:640  current_step:640\n",
      "speed: 0.350s, remaining training time: 00:03:33:50\n",
      "total_losses:1.104\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.430\n",
      "fast_reg_loss:0.634\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:40: global_step:660  current_step:660\n",
      "speed: 0.328s, remaining training time: 00:03:20:25\n",
      "total_losses:0.489\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.165\n",
      "fast_reg_loss:0.306\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:46: global_step:680  current_step:680\n",
      "speed: 0.310s, remaining training time: 00:03:09:09\n",
      "total_losses:0.700\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.224\n",
      "fast_reg_loss:0.441\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:53: global_step:700  current_step:700\n",
      "speed: 0.346s, remaining training time: 00:03:30:53\n",
      "total_losses:1.109\n",
      "rpn_cls_loss:0.071\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.389\n",
      "fast_reg_loss:0.629\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:38:59: global_step:720  current_step:720\n",
      "speed: 0.316s, remaining training time: 00:03:12:33\n",
      "total_losses:0.733\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.245\n",
      "fast_reg_loss:0.451\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:39:06: global_step:740  current_step:740\n",
      "speed: 0.308s, remaining training time: 00:03:07:25\n",
      "total_losses:0.317\n",
      "rpn_cls_loss:0.010\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.109\n",
      "fast_reg_loss:0.197\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:39:13: global_step:760  current_step:760\n",
      "speed: 0.350s, remaining training time: 00:03:33:22\n",
      "total_losses:0.956\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.328\n",
      "fast_reg_loss:0.607\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:39:20: global_step:780  current_step:780\n",
      "speed: 0.337s, remaining training time: 00:03:25:07\n",
      "total_losses:0.861\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.334\n",
      "fast_reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:39:34: global_step:820  current_step:820\n",
      "speed: 0.327s, remaining training time: 00:03:18:47\n",
      "total_losses:0.484\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.204\n",
      "fast_reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:39:40: global_step:840  current_step:840\n",
      "speed: 0.346s, remaining training time: 00:03:30:28\n",
      "total_losses:0.473\n",
      "rpn_cls_loss:0.053\n",
      "rpn_reg_loss:0.026\n",
      "fast_cls_loss:0.161\n",
      "fast_reg_loss:0.234\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:39:47: global_step:860  current_step:860\n",
      "speed: 0.328s, remaining training time: 00:03:19:16\n",
      "total_losses:0.605\n",
      "rpn_cls_loss:0.078\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.282\n",
      "fast_reg_loss:0.233\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:39:54: global_step:880  current_step:880\n",
      "speed: 0.328s, remaining training time: 00:03:19:00\n",
      "total_losses:0.432\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.169\n",
      "fast_reg_loss:0.210\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:00: global_step:900  current_step:900\n",
      "speed: 0.310s, remaining training time: 00:03:08:14\n",
      "total_losses:0.516\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.236\n",
      "fast_reg_loss:0.237\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:07: global_step:920  current_step:920\n",
      "speed: 0.347s, remaining training time: 00:03:30:27\n",
      "total_losses:0.925\n",
      "rpn_cls_loss:0.050\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.410\n",
      "fast_reg_loss:0.452\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:14: global_step:940  current_step:940\n",
      "speed: 0.326s, remaining training time: 00:03:17:42\n",
      "total_losses:0.314\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.139\n",
      "fast_reg_loss:0.114\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:21: global_step:960  current_step:960\n",
      "speed: 0.317s, remaining training time: 00:03:11:53\n",
      "total_losses:0.429\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.190\n",
      "fast_reg_loss:0.202\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:27: global_step:980  current_step:980\n",
      "speed: 0.363s, remaining training time: 00:03:39:33\n",
      "total_losses:1.056\n",
      "rpn_cls_loss:0.068\n",
      "rpn_reg_loss:0.023\n",
      "fast_cls_loss:0.424\n",
      "fast_reg_loss:0.541\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:41: global_step:1020  current_step:1020\n",
      "speed: 0.324s, remaining training time: 00:03:16:01\n",
      "total_losses:0.501\n",
      "rpn_cls_loss:0.011\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.147\n",
      "fast_reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:47: global_step:1040  current_step:1040\n",
      "speed: 0.353s, remaining training time: 00:03:33:14\n",
      "total_losses:0.888\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.325\n",
      "fast_reg_loss:0.519\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:40:54: global_step:1060  current_step:1060\n",
      "speed: 0.332s, remaining training time: 00:03:20:44\n",
      "total_losses:0.788\n",
      "rpn_cls_loss:0.012\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.275\n",
      "fast_reg_loss:0.495\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:01: global_step:1080  current_step:1080\n",
      "speed: 0.316s, remaining training time: 00:03:11:01\n",
      "total_losses:0.395\n",
      "rpn_cls_loss:0.007\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.177\n",
      "fast_reg_loss:0.209\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:07: global_step:1100  current_step:1100\n",
      "speed: 0.360s, remaining training time: 00:03:36:57\n",
      "total_losses:1.202\n",
      "rpn_cls_loss:0.098\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.487\n",
      "fast_reg_loss:0.600\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:41:15: global_step:1120  current_step:1120\n",
      "speed: 0.315s, remaining training time: 00:03:09:46\n",
      "total_losses:0.443\n",
      "rpn_cls_loss:0.084\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.154\n",
      "fast_reg_loss:0.202\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:21: global_step:1140  current_step:1140\n",
      "speed: 0.320s, remaining training time: 00:03:13:01\n",
      "total_losses:0.344\n",
      "rpn_cls_loss:0.005\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.161\n",
      "fast_reg_loss:0.170\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:28: global_step:1160  current_step:1160\n",
      "speed: 0.324s, remaining training time: 00:03:15:26\n",
      "total_losses:0.990\n",
      "rpn_cls_loss:0.024\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.359\n",
      "fast_reg_loss:0.601\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:35: global_step:1180  current_step:1180\n",
      "speed: 0.338s, remaining training time: 00:03:23:24\n",
      "total_losses:0.954\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.295\n",
      "fast_reg_loss:0.620\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:48: global_step:1220  current_step:1220\n",
      "speed: 0.375s, remaining training time: 00:03:45:43\n",
      "total_losses:1.098\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.022\n",
      "fast_cls_loss:0.384\n",
      "fast_reg_loss:0.665\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:41:55: global_step:1240  current_step:1240\n",
      "speed: 0.353s, remaining training time: 00:03:31:54\n",
      "total_losses:0.749\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.337\n",
      "fast_reg_loss:0.345\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:02: global_step:1260  current_step:1260\n",
      "speed: 0.331s, remaining training time: 00:03:18:31\n",
      "total_losses:0.893\n",
      "rpn_cls_loss:0.053\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.324\n",
      "fast_reg_loss:0.504\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:08: global_step:1280  current_step:1280\n",
      "speed: 0.309s, remaining training time: 00:03:05:13\n",
      "total_losses:0.245\n",
      "rpn_cls_loss:0.010\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.128\n",
      "fast_reg_loss:0.106\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:15: global_step:1300  current_step:1300\n",
      "speed: 0.345s, remaining training time: 00:03:26:47\n",
      "total_losses:1.196\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.430\n",
      "fast_reg_loss:0.707\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:22: global_step:1320  current_step:1320\n",
      "speed: 0.337s, remaining training time: 00:03:21:51\n",
      "total_losses:0.950\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.303\n",
      "fast_reg_loss:0.619\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:29: global_step:1340  current_step:1340\n",
      "speed: 0.361s, remaining training time: 00:03:36:26\n",
      "total_losses:0.869\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.375\n",
      "fast_reg_loss:0.453\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:35: global_step:1360  current_step:1360\n",
      "speed: 0.324s, remaining training time: 00:03:14:07\n",
      "total_losses:0.895\n",
      "rpn_cls_loss:0.019\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.322\n",
      "fast_reg_loss:0.542\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:42: global_step:1380  current_step:1380\n",
      "speed: 0.320s, remaining training time: 00:03:11:51\n",
      "total_losses:0.565\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.397\n",
      "fast_reg_loss:0.142\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:42:56: global_step:1420  current_step:1420\n",
      "speed: 0.361s, remaining training time: 00:03:36:04\n",
      "total_losses:1.294\n",
      "rpn_cls_loss:0.139\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.480\n",
      "fast_reg_loss:0.659\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:03: global_step:1440  current_step:1440\n",
      "speed: 0.358s, remaining training time: 00:03:33:58\n",
      "total_losses:1.000\n",
      "rpn_cls_loss:0.130\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.367\n",
      "fast_reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:09: global_step:1460  current_step:1460\n",
      "speed: 0.344s, remaining training time: 00:03:25:38\n",
      "total_losses:0.887\n",
      "rpn_cls_loss:0.010\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.336\n",
      "fast_reg_loss:0.531\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:16: global_step:1480  current_step:1480\n",
      "speed: 0.361s, remaining training time: 00:03:35:43\n",
      "total_losses:0.764\n",
      "rpn_cls_loss:0.017\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.267\n",
      "fast_reg_loss:0.467\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:43:23: global_step:1500  current_step:1500\n",
      "speed: 0.322s, remaining training time: 00:03:12:13\n",
      "total_losses:0.796\n",
      "rpn_cls_loss:0.014\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.319\n",
      "fast_reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:30: global_step:1520  current_step:1520\n",
      "speed: 0.359s, remaining training time: 00:03:33:58\n",
      "total_losses:0.750\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.275\n",
      "fast_reg_loss:0.439\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:37: global_step:1540  current_step:1540\n",
      "speed: 0.329s, remaining training time: 00:03:16:17\n",
      "total_losses:0.837\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.297\n",
      "fast_reg_loss:0.495\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:43: global_step:1560  current_step:1560\n",
      "speed: 0.331s, remaining training time: 00:03:17:25\n",
      "total_losses:0.729\n",
      "rpn_cls_loss:0.005\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.170\n",
      "fast_reg_loss:0.551\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:43:50: global_step:1580  current_step:1580\n",
      "speed: 0.330s, remaining training time: 00:03:16:24\n",
      "total_losses:0.873\n",
      "rpn_cls_loss:0.006\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.326\n",
      "fast_reg_loss:0.526\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:03: global_step:1620  current_step:1620\n",
      "speed: 0.320s, remaining training time: 00:03:10:29\n",
      "total_losses:0.731\n",
      "rpn_cls_loss:0.004\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.233\n",
      "fast_reg_loss:0.491\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:10: global_step:1640  current_step:1640\n",
      "speed: 0.317s, remaining training time: 00:03:08:31\n",
      "total_losses:0.570\n",
      "rpn_cls_loss:0.004\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.202\n",
      "fast_reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:17: global_step:1660  current_step:1660\n",
      "speed: 0.314s, remaining training time: 00:03:06:46\n",
      "total_losses:1.039\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.426\n",
      "fast_reg_loss:0.588\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:23: global_step:1680  current_step:1680\n",
      "speed: 0.346s, remaining training time: 00:03:25:16\n",
      "total_losses:0.850\n",
      "rpn_cls_loss:0.017\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.335\n",
      "fast_reg_loss:0.488\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:30: global_step:1700  current_step:1700\n",
      "speed: 0.321s, remaining training time: 00:03:10:24\n",
      "total_losses:0.438\n",
      "rpn_cls_loss:0.005\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.142\n",
      "fast_reg_loss:0.284\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:36: global_step:1720  current_step:1720\n",
      "speed: 0.326s, remaining training time: 00:03:13:18\n",
      "total_losses:0.659\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.245\n",
      "fast_reg_loss:0.375\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:43: global_step:1740  current_step:1740\n",
      "speed: 0.329s, remaining training time: 00:03:14:59\n",
      "total_losses:0.598\n",
      "rpn_cls_loss:0.014\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.224\n",
      "fast_reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:50: global_step:1760  current_step:1760\n",
      "speed: 0.336s, remaining training time: 00:03:19:18\n",
      "total_losses:0.711\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.263\n",
      "fast_reg_loss:0.420\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:44:56: global_step:1780  current_step:1780\n",
      "speed: 0.323s, remaining training time: 00:03:11:15\n",
      "total_losses:0.657\n",
      "rpn_cls_loss:0.017\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.222\n",
      "fast_reg_loss:0.412\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:10: global_step:1820  current_step:1820\n",
      "speed: 0.354s, remaining training time: 00:03:29:16\n",
      "total_losses:1.321\n",
      "rpn_cls_loss:0.060\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.533\n",
      "fast_reg_loss:0.713\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:16: global_step:1840  current_step:1840\n",
      "speed: 0.320s, remaining training time: 00:03:08:56\n",
      "total_losses:0.896\n",
      "rpn_cls_loss:0.086\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.328\n",
      "fast_reg_loss:0.468\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:23: global_step:1860  current_step:1860\n",
      "speed: 0.324s, remaining training time: 00:03:11:12\n",
      "total_losses:0.153\n",
      "rpn_cls_loss:0.011\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.068\n",
      "fast_reg_loss:0.072\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:45:31: global_step:1880  current_step:1880\n",
      "speed: 0.319s, remaining training time: 00:03:08:35\n",
      "total_losses:0.694\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.252\n",
      "fast_reg_loss:0.404\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:37: global_step:1900  current_step:1900\n",
      "speed: 0.322s, remaining training time: 00:03:09:49\n",
      "total_losses:0.329\n",
      "rpn_cls_loss:0.014\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.121\n",
      "fast_reg_loss:0.194\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:44: global_step:1920  current_step:1920\n",
      "speed: 0.339s, remaining training time: 00:03:20:10\n",
      "total_losses:1.658\n",
      "rpn_cls_loss:0.264\n",
      "rpn_reg_loss:0.037\n",
      "fast_cls_loss:0.807\n",
      "fast_reg_loss:0.550\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:50: global_step:1940  current_step:1940\n",
      "speed: 0.317s, remaining training time: 00:03:06:54\n",
      "total_losses:0.294\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.119\n",
      "fast_reg_loss:0.105\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:45:57: global_step:1960  current_step:1960\n",
      "speed: 0.354s, remaining training time: 00:03:28:13\n",
      "total_losses:1.065\n",
      "rpn_cls_loss:0.061\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.505\n",
      "fast_reg_loss:0.484\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:04: global_step:1980  current_step:1980\n",
      "speed: 0.309s, remaining training time: 00:03:01:38\n",
      "total_losses:0.428\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.163\n",
      "fast_reg_loss:0.232\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:17: global_step:2020  current_step:2020\n",
      "speed: 0.356s, remaining training time: 00:03:29:05\n",
      "total_losses:0.946\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.365\n",
      "fast_reg_loss:0.538\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:24: global_step:2040  current_step:2040\n",
      "speed: 0.302s, remaining training time: 00:02:57:21\n",
      "total_losses:0.327\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.191\n",
      "fast_reg_loss:0.117\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:30: global_step:2060  current_step:2060\n",
      "speed: 0.381s, remaining training time: 00:03:43:51\n",
      "total_losses:1.147\n",
      "rpn_cls_loss:0.075\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.376\n",
      "fast_reg_loss:0.680\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:37: global_step:2080  current_step:2080\n",
      "speed: 0.319s, remaining training time: 00:03:07:16\n",
      "total_losses:1.275\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.280\n",
      "fast_reg_loss:0.966\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:44: global_step:2100  current_step:2100\n",
      "speed: 0.362s, remaining training time: 00:03:32:21\n",
      "total_losses:1.054\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.387\n",
      "fast_reg_loss:0.622\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:51: global_step:2120  current_step:2120\n",
      "speed: 0.355s, remaining training time: 00:03:27:58\n",
      "total_losses:1.280\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.622\n",
      "fast_reg_loss:0.597\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:46:57: global_step:2140  current_step:2140\n",
      "speed: 0.358s, remaining training time: 00:03:29:54\n",
      "total_losses:0.946\n",
      "rpn_cls_loss:0.187\n",
      "rpn_reg_loss:0.043\n",
      "fast_cls_loss:0.375\n",
      "fast_reg_loss:0.342\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:04: global_step:2160  current_step:2160\n",
      "speed: 0.332s, remaining training time: 00:03:14:32\n",
      "total_losses:0.387\n",
      "rpn_cls_loss:0.072\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.146\n",
      "fast_reg_loss:0.154\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:11: global_step:2180  current_step:2180\n",
      "speed: 0.324s, remaining training time: 00:03:09:40\n",
      "total_losses:0.720\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.295\n",
      "fast_reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:24: global_step:2220  current_step:2220\n",
      "speed: 0.302s, remaining training time: 00:02:56:46\n",
      "total_losses:0.219\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.122\n",
      "fast_reg_loss:0.064\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:47:31: global_step:2240  current_step:2240\n",
      "speed: 0.325s, remaining training time: 00:03:09:42\n",
      "total_losses:0.455\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.153\n",
      "fast_reg_loss:0.256\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:38: global_step:2260  current_step:2260\n",
      "speed: 0.346s, remaining training time: 00:03:22:17\n",
      "total_losses:0.649\n",
      "rpn_cls_loss:0.088\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.264\n",
      "fast_reg_loss:0.287\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:45: global_step:2280  current_step:2280\n",
      "speed: 0.329s, remaining training time: 00:03:11:57\n",
      "total_losses:0.531\n",
      "rpn_cls_loss:0.058\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.209\n",
      "fast_reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:51: global_step:2300  current_step:2300\n",
      "speed: 0.332s, remaining training time: 00:03:13:32\n",
      "total_losses:0.448\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.167\n",
      "fast_reg_loss:0.243\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:47:58: global_step:2320  current_step:2320\n",
      "speed: 0.345s, remaining training time: 00:03:20:59\n",
      "total_losses:0.586\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.235\n",
      "fast_reg_loss:0.292\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:05: global_step:2340  current_step:2340\n",
      "speed: 0.358s, remaining training time: 00:03:28:49\n",
      "total_losses:1.180\n",
      "rpn_cls_loss:0.115\n",
      "rpn_reg_loss:0.023\n",
      "fast_cls_loss:0.343\n",
      "fast_reg_loss:0.698\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:12: global_step:2360  current_step:2360\n",
      "speed: 0.323s, remaining training time: 00:03:07:55\n",
      "total_losses:0.551\n",
      "rpn_cls_loss:0.103\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.172\n",
      "fast_reg_loss:0.268\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:18: global_step:2380  current_step:2380\n",
      "speed: 0.340s, remaining training time: 00:03:17:51\n",
      "total_losses:0.883\n",
      "rpn_cls_loss:0.103\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.255\n",
      "fast_reg_loss:0.511\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:32: global_step:2420  current_step:2420\n",
      "speed: 0.375s, remaining training time: 00:03:38:04\n",
      "total_losses:1.209\n",
      "rpn_cls_loss:0.091\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.422\n",
      "fast_reg_loss:0.681\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:38: global_step:2440  current_step:2440\n",
      "speed: 0.352s, remaining training time: 00:03:24:31\n",
      "total_losses:0.933\n",
      "rpn_cls_loss:0.050\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.326\n",
      "fast_reg_loss:0.545\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:45: global_step:2460  current_step:2460\n",
      "speed: 0.360s, remaining training time: 00:03:28:56\n",
      "total_losses:0.740\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.317\n",
      "fast_reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:52: global_step:2480  current_step:2480\n",
      "speed: 0.320s, remaining training time: 00:03:05:44\n",
      "total_losses:0.135\n",
      "rpn_cls_loss:0.049\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.049\n",
      "fast_reg_loss:0.033\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:48:58: global_step:2500  current_step:2500\n",
      "speed: 0.323s, remaining training time: 00:03:07:11\n",
      "total_losses:0.215\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.071\n",
      "fast_reg_loss:0.101\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:05: global_step:2520  current_step:2520\n",
      "speed: 0.326s, remaining training time: 00:03:08:51\n",
      "total_losses:0.278\n",
      "rpn_cls_loss:0.053\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.102\n",
      "fast_reg_loss:0.115\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:11: global_step:2540  current_step:2540\n",
      "speed: 0.368s, remaining training time: 00:03:33:13\n",
      "total_losses:0.824\n",
      "rpn_cls_loss:0.058\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.398\n",
      "fast_reg_loss:0.350\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:18: global_step:2560  current_step:2560\n",
      "speed: 0.323s, remaining training time: 00:03:07:04\n",
      "total_losses:0.238\n",
      "rpn_cls_loss:0.038\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.170\n",
      "fast_reg_loss:0.027\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:25: global_step:2580  current_step:2580\n",
      "speed: 0.366s, remaining training time: 00:03:31:53\n",
      "total_losses:0.627\n",
      "rpn_cls_loss:0.108\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.219\n",
      "fast_reg_loss:0.284\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:49:39: global_step:2620  current_step:2620\n",
      "speed: 0.333s, remaining training time: 00:03:12:40\n",
      "total_losses:0.719\n",
      "rpn_cls_loss:0.099\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.260\n",
      "fast_reg_loss:0.352\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:46: global_step:2640  current_step:2640\n",
      "speed: 0.322s, remaining training time: 00:03:05:47\n",
      "total_losses:0.124\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.074\n",
      "fast_reg_loss:0.032\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:52: global_step:2660  current_step:2660\n",
      "speed: 0.330s, remaining training time: 00:03:10:20\n",
      "total_losses:0.117\n",
      "rpn_cls_loss:0.019\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.031\n",
      "fast_reg_loss:0.064\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:49:59: global_step:2680  current_step:2680\n",
      "speed: 0.336s, remaining training time: 00:03:13:55\n",
      "total_losses:0.461\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.199\n",
      "fast_reg_loss:0.206\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:06: global_step:2700  current_step:2700\n",
      "speed: 0.370s, remaining training time: 00:03:33:17\n",
      "total_losses:1.176\n",
      "rpn_cls_loss:0.099\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:0.482\n",
      "fast_reg_loss:0.577\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:13: global_step:2720  current_step:2720\n",
      "speed: 0.327s, remaining training time: 00:03:08:20\n",
      "total_losses:0.374\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.174\n",
      "fast_reg_loss:0.149\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:19: global_step:2740  current_step:2740\n",
      "speed: 0.351s, remaining training time: 00:03:22:23\n",
      "total_losses:0.583\n",
      "rpn_cls_loss:0.128\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.152\n",
      "fast_reg_loss:0.291\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:26: global_step:2760  current_step:2760\n",
      "speed: 0.307s, remaining training time: 00:02:56:29\n",
      "total_losses:0.123\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.046\n",
      "fast_reg_loss:0.051\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:32: global_step:2780  current_step:2780\n",
      "speed: 0.336s, remaining training time: 00:03:13:19\n",
      "total_losses:0.422\n",
      "rpn_cls_loss:0.076\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.126\n",
      "fast_reg_loss:0.213\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:46: global_step:2820  current_step:2820\n",
      "speed: 0.354s, remaining training time: 00:03:23:13\n",
      "total_losses:0.507\n",
      "rpn_cls_loss:0.062\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.180\n",
      "fast_reg_loss:0.257\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:50:53: global_step:2840  current_step:2840\n",
      "speed: 0.357s, remaining training time: 00:03:24:54\n",
      "total_losses:1.058\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.375\n",
      "fast_reg_loss:0.613\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:00: global_step:2860  current_step:2860\n",
      "speed: 0.324s, remaining training time: 00:03:06:14\n",
      "total_losses:0.323\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.121\n",
      "fast_reg_loss:0.162\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:07: global_step:2880  current_step:2880\n",
      "speed: 0.313s, remaining training time: 00:02:59:21\n",
      "total_losses:0.303\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.097\n",
      "fast_reg_loss:0.163\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:13: global_step:2900  current_step:2900\n",
      "speed: 0.309s, remaining training time: 00:02:57:20\n",
      "total_losses:0.396\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.157\n",
      "fast_reg_loss:0.210\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:20: global_step:2920  current_step:2920\n",
      "speed: 0.324s, remaining training time: 00:03:05:24\n",
      "total_losses:0.146\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.064\n",
      "fast_reg_loss:0.053\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:27: global_step:2940  current_step:2940\n",
      "speed: 0.317s, remaining training time: 00:03:01:44\n",
      "total_losses:0.370\n",
      "rpn_cls_loss:0.038\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.150\n",
      "fast_reg_loss:0.177\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:33: global_step:2960  current_step:2960\n",
      "speed: 0.334s, remaining training time: 00:03:10:56\n",
      "total_losses:0.262\n",
      "rpn_cls_loss:0.022\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.091\n",
      "fast_reg_loss:0.148\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:51:40: global_step:2980  current_step:2980\n",
      "speed: 0.339s, remaining training time: 00:03:14:02\n",
      "total_losses:0.686\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.273\n",
      "fast_reg_loss:0.372\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:51:54: global_step:3020  current_step:3020\n",
      "speed: 0.316s, remaining training time: 00:03:00:28\n",
      "total_losses:0.323\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.105\n",
      "fast_reg_loss:0.179\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:01: global_step:3040  current_step:3040\n",
      "speed: 0.342s, remaining training time: 00:03:15:18\n",
      "total_losses:0.944\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.255\n",
      "fast_reg_loss:0.624\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:07: global_step:3060  current_step:3060\n",
      "speed: 0.358s, remaining training time: 00:03:24:20\n",
      "total_losses:0.998\n",
      "rpn_cls_loss:0.103\n",
      "rpn_reg_loss:0.021\n",
      "fast_cls_loss:0.369\n",
      "fast_reg_loss:0.504\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:14: global_step:3080  current_step:3080\n",
      "speed: 0.347s, remaining training time: 00:03:17:59\n",
      "total_losses:0.548\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.169\n",
      "fast_reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:21: global_step:3100  current_step:3100\n",
      "speed: 0.331s, remaining training time: 00:03:08:35\n",
      "total_losses:0.516\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.230\n",
      "fast_reg_loss:0.234\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:27: global_step:3120  current_step:3120\n",
      "speed: 0.362s, remaining training time: 00:03:26:09\n",
      "total_losses:0.870\n",
      "rpn_cls_loss:0.099\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.301\n",
      "fast_reg_loss:0.456\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:34: global_step:3140  current_step:3140\n",
      "speed: 0.319s, remaining training time: 00:03:01:38\n",
      "total_losses:0.443\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.209\n",
      "fast_reg_loss:0.190\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:40: global_step:3160  current_step:3160\n",
      "speed: 0.335s, remaining training time: 00:03:10:30\n",
      "total_losses:0.357\n",
      "rpn_cls_loss:0.039\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.113\n",
      "fast_reg_loss:0.193\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:52:47: global_step:3180  current_step:3180\n",
      "speed: 0.317s, remaining training time: 00:03:00:20\n",
      "total_losses:0.139\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.049\n",
      "fast_reg_loss:0.073\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:00: global_step:3220  current_step:3220\n",
      "speed: 0.363s, remaining training time: 00:03:26:15\n",
      "total_losses:0.754\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.317\n",
      "fast_reg_loss:0.392\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:07: global_step:3240  current_step:3240\n",
      "speed: 0.329s, remaining training time: 00:03:06:52\n",
      "total_losses:0.290\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.134\n",
      "fast_reg_loss:0.122\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:14: global_step:3260  current_step:3260\n",
      "speed: 0.382s, remaining training time: 00:03:36:46\n",
      "total_losses:0.824\n",
      "rpn_cls_loss:0.059\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.423\n",
      "fast_reg_loss:0.326\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:21: global_step:3280  current_step:3280\n",
      "speed: 0.364s, remaining training time: 00:03:26:16\n",
      "total_losses:0.834\n",
      "rpn_cls_loss:0.091\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.329\n",
      "fast_reg_loss:0.403\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:27: global_step:3300  current_step:3300\n",
      "speed: 0.317s, remaining training time: 00:02:59:43\n",
      "total_losses:0.202\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.057\n",
      "fast_reg_loss:0.087\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:34: global_step:3320  current_step:3320\n",
      "speed: 0.300s, remaining training time: 00:02:50:05\n",
      "total_losses:0.351\n",
      "rpn_cls_loss:0.058\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.138\n",
      "fast_reg_loss:0.148\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:40: global_step:3340  current_step:3340\n",
      "speed: 0.314s, remaining training time: 00:02:57:55\n",
      "total_losses:0.176\n",
      "rpn_cls_loss:0.050\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.044\n",
      "fast_reg_loss:0.077\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:53:48: global_step:3360  current_step:3360\n",
      "speed: 0.308s, remaining training time: 00:02:54:11\n",
      "total_losses:0.090\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.028\n",
      "fast_reg_loss:0.033\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:53:55: global_step:3380  current_step:3380\n",
      "speed: 0.313s, remaining training time: 00:02:56:45\n",
      "total_losses:0.281\n",
      "rpn_cls_loss:0.063\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.061\n",
      "fast_reg_loss:0.152\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:08: global_step:3420  current_step:3420\n",
      "speed: 0.381s, remaining training time: 00:03:34:51\n",
      "total_losses:0.657\n",
      "rpn_cls_loss:0.134\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.226\n",
      "fast_reg_loss:0.282\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:15: global_step:3440  current_step:3440\n",
      "speed: 0.342s, remaining training time: 00:03:12:53\n",
      "total_losses:0.392\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.147\n",
      "fast_reg_loss:0.193\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:21: global_step:3460  current_step:3460\n",
      "speed: 0.303s, remaining training time: 00:02:51:03\n",
      "total_losses:0.171\n",
      "rpn_cls_loss:0.043\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.054\n",
      "fast_reg_loss:0.070\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:28: global_step:3480  current_step:3480\n",
      "speed: 0.329s, remaining training time: 00:03:05:23\n",
      "total_losses:0.326\n",
      "rpn_cls_loss:0.038\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.114\n",
      "fast_reg_loss:0.168\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:35: global_step:3500  current_step:3500\n",
      "speed: 0.366s, remaining training time: 00:03:26:15\n",
      "total_losses:0.476\n",
      "rpn_cls_loss:0.050\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.169\n",
      "fast_reg_loss:0.248\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:41: global_step:3520  current_step:3520\n",
      "speed: 0.340s, remaining training time: 00:03:11:31\n",
      "total_losses:0.494\n",
      "rpn_cls_loss:0.068\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.192\n",
      "fast_reg_loss:0.224\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:48: global_step:3540  current_step:3540\n",
      "speed: 0.318s, remaining training time: 00:02:58:51\n",
      "total_losses:0.257\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.101\n",
      "fast_reg_loss:0.124\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:54:55: global_step:3560  current_step:3560\n",
      "speed: 0.334s, remaining training time: 00:03:07:46\n",
      "total_losses:0.318\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.121\n",
      "fast_reg_loss:0.156\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:01: global_step:3580  current_step:3580\n",
      "speed: 0.330s, remaining training time: 00:03:05:31\n",
      "total_losses:0.453\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.161\n",
      "fast_reg_loss:0.257\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:15: global_step:3620  current_step:3620\n",
      "speed: 0.319s, remaining training time: 00:02:58:49\n",
      "total_losses:0.208\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.072\n",
      "fast_reg_loss:0.086\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:21: global_step:3640  current_step:3640\n",
      "speed: 0.323s, remaining training time: 00:03:01:17\n",
      "total_losses:0.106\n",
      "rpn_cls_loss:0.020\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.042\n",
      "fast_reg_loss:0.043\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:28: global_step:3660  current_step:3660\n",
      "speed: 0.337s, remaining training time: 00:03:09:07\n",
      "total_losses:0.360\n",
      "rpn_cls_loss:0.055\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.125\n",
      "fast_reg_loss:0.174\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:34: global_step:3680  current_step:3680\n",
      "speed: 0.329s, remaining training time: 00:03:04:16\n",
      "total_losses:0.176\n",
      "rpn_cls_loss:0.049\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.057\n",
      "fast_reg_loss:0.065\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:41: global_step:3700  current_step:3700\n",
      "speed: 0.313s, remaining training time: 00:02:55:20\n",
      "total_losses:0.126\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.044\n",
      "fast_reg_loss:0.044\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:55:48: global_step:3720  current_step:3720\n",
      "speed: 0.363s, remaining training time: 00:03:23:01\n",
      "total_losses:0.560\n",
      "rpn_cls_loss:0.063\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.179\n",
      "fast_reg_loss:0.304\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:55:55: global_step:3740  current_step:3740\n",
      "speed: 0.352s, remaining training time: 00:03:16:40\n",
      "total_losses:0.569\n",
      "rpn_cls_loss:0.106\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.154\n",
      "fast_reg_loss:0.292\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:02: global_step:3760  current_step:3760\n",
      "speed: 0.349s, remaining training time: 00:03:15:04\n",
      "total_losses:0.405\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.158\n",
      "fast_reg_loss:0.203\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:08: global_step:3780  current_step:3780\n",
      "speed: 0.318s, remaining training time: 00:02:57:47\n",
      "total_losses:0.299\n",
      "rpn_cls_loss:0.096\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.071\n",
      "fast_reg_loss:0.123\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:22: global_step:3820  current_step:3820\n",
      "speed: 0.321s, remaining training time: 00:02:59:17\n",
      "total_losses:0.345\n",
      "rpn_cls_loss:0.056\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.138\n",
      "fast_reg_loss:0.145\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:28: global_step:3840  current_step:3840\n",
      "speed: 0.322s, remaining training time: 00:02:59:45\n",
      "total_losses:0.061\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.016\n",
      "fast_reg_loss:0.016\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:35: global_step:3860  current_step:3860\n",
      "speed: 0.345s, remaining training time: 00:03:12:25\n",
      "total_losses:0.347\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.113\n",
      "fast_reg_loss:0.196\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:42: global_step:3880  current_step:3880\n",
      "speed: 0.313s, remaining training time: 00:02:54:10\n",
      "total_losses:0.074\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.030\n",
      "fast_reg_loss:0.024\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:48: global_step:3900  current_step:3900\n",
      "speed: 0.350s, remaining training time: 00:03:15:00\n",
      "total_losses:0.595\n",
      "rpn_cls_loss:0.059\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.210\n",
      "fast_reg_loss:0.313\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:56:55: global_step:3920  current_step:3920\n",
      "speed: 0.354s, remaining training time: 00:03:16:44\n",
      "total_losses:0.723\n",
      "rpn_cls_loss:0.160\n",
      "rpn_reg_loss:0.022\n",
      "fast_cls_loss:0.207\n",
      "fast_reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:02: global_step:3940  current_step:3940\n",
      "speed: 0.330s, remaining training time: 00:03:03:35\n",
      "total_losses:0.447\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.147\n",
      "fast_reg_loss:0.237\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:08: global_step:3960  current_step:3960\n",
      "speed: 0.342s, remaining training time: 00:03:09:59\n",
      "total_losses:0.867\n",
      "rpn_cls_loss:0.096\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.322\n",
      "fast_reg_loss:0.430\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:15: global_step:3980  current_step:3980\n",
      "speed: 0.310s, remaining training time: 00:02:52:19\n",
      "total_losses:0.296\n",
      "rpn_cls_loss:0.022\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.141\n",
      "fast_reg_loss:0.131\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:28: global_step:4020  current_step:4020\n",
      "speed: 0.325s, remaining training time: 00:03:00:21\n",
      "total_losses:0.515\n",
      "rpn_cls_loss:0.065\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.174\n",
      "fast_reg_loss:0.266\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:35: global_step:4040  current_step:4040\n",
      "speed: 0.384s, remaining training time: 00:03:33:05\n",
      "total_losses:0.724\n",
      "rpn_cls_loss:0.078\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.303\n",
      "fast_reg_loss:0.327\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:42: global_step:4060  current_step:4060\n",
      "speed: 0.314s, remaining training time: 00:02:53:48\n",
      "total_losses:0.150\n",
      "rpn_cls_loss:0.039\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.051\n",
      "fast_reg_loss:0.055\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:48: global_step:4080  current_step:4080\n",
      "speed: 0.355s, remaining training time: 00:03:16:41\n",
      "total_losses:0.474\n",
      "rpn_cls_loss:0.070\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.152\n",
      "fast_reg_loss:0.238\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:57:55: global_step:4100  current_step:4100\n",
      "speed: 0.344s, remaining training time: 00:03:10:18\n",
      "total_losses:0.307\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.110\n",
      "fast_reg_loss:0.140\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 20:58:03: global_step:4120  current_step:4120\n",
      "speed: 0.346s, remaining training time: 00:03:11:13\n",
      "total_losses:0.300\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.102\n",
      "fast_reg_loss:0.134\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:09: global_step:4140  current_step:4140\n",
      "speed: 0.319s, remaining training time: 00:02:56:01\n",
      "total_losses:0.254\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.079\n",
      "fast_reg_loss:0.147\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:16: global_step:4160  current_step:4160\n",
      "speed: 0.321s, remaining training time: 00:02:57:13\n",
      "total_losses:0.115\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.045\n",
      "fast_reg_loss:0.038\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:23: global_step:4180  current_step:4180\n",
      "speed: 0.320s, remaining training time: 00:02:56:27\n",
      "total_losses:0.245\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.064\n",
      "fast_reg_loss:0.141\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:36: global_step:4220  current_step:4220\n",
      "speed: 0.334s, remaining training time: 00:03:04:01\n",
      "total_losses:0.443\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.155\n",
      "fast_reg_loss:0.251\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:43: global_step:4240  current_step:4240\n",
      "speed: 0.310s, remaining training time: 00:02:50:48\n",
      "total_losses:0.179\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.061\n",
      "fast_reg_loss:0.084\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:49: global_step:4260  current_step:4260\n",
      "speed: 0.318s, remaining training time: 00:02:55:01\n",
      "total_losses:0.156\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.079\n",
      "fast_reg_loss:0.028\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:58:56: global_step:4280  current_step:4280\n",
      "speed: 0.326s, remaining training time: 00:02:59:40\n",
      "total_losses:0.186\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.053\n",
      "fast_reg_loss:0.091\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:03: global_step:4300  current_step:4300\n",
      "speed: 0.309s, remaining training time: 00:02:49:48\n",
      "total_losses:0.272\n",
      "rpn_cls_loss:0.066\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.107\n",
      "fast_reg_loss:0.095\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:09: global_step:4320  current_step:4320\n",
      "speed: 0.337s, remaining training time: 00:03:05:14\n",
      "total_losses:0.256\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.085\n",
      "fast_reg_loss:0.126\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:16: global_step:4340  current_step:4340\n",
      "speed: 0.321s, remaining training time: 00:02:56:28\n",
      "total_losses:0.160\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.051\n",
      "fast_reg_loss:0.065\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:23: global_step:4360  current_step:4360\n",
      "speed: 0.374s, remaining training time: 00:03:25:22\n",
      "total_losses:0.748\n",
      "rpn_cls_loss:0.119\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.221\n",
      "fast_reg_loss:0.389\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:29: global_step:4380  current_step:4380\n",
      "speed: 0.342s, remaining training time: 00:03:07:29\n",
      "total_losses:0.397\n",
      "rpn_cls_loss:0.086\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.093\n",
      "fast_reg_loss:0.207\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:43: global_step:4420  current_step:4420\n",
      "speed: 0.345s, remaining training time: 00:03:08:51\n",
      "total_losses:0.405\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.137\n",
      "fast_reg_loss:0.187\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:50: global_step:4440  current_step:4440\n",
      "speed: 0.329s, remaining training time: 00:03:00:27\n",
      "total_losses:0.266\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.104\n",
      "fast_reg_loss:0.126\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 20:59:56: global_step:4460  current_step:4460\n",
      "speed: 0.306s, remaining training time: 00:02:47:38\n",
      "total_losses:0.286\n",
      "rpn_cls_loss:0.050\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.103\n",
      "fast_reg_loss:0.126\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:00:04: global_step:4480  current_step:4480\n",
      "speed: 0.339s, remaining training time: 00:03:05:28\n",
      "total_losses:0.876\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.461\n",
      "fast_reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:11: global_step:4500  current_step:4500\n",
      "speed: 0.319s, remaining training time: 00:02:54:39\n",
      "total_losses:0.278\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.074\n",
      "fast_reg_loss:0.168\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:17: global_step:4520  current_step:4520\n",
      "speed: 0.317s, remaining training time: 00:02:53:26\n",
      "total_losses:0.079\n",
      "rpn_cls_loss:0.019\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.028\n",
      "fast_reg_loss:0.029\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:24: global_step:4540  current_step:4540\n",
      "speed: 0.327s, remaining training time: 00:02:58:37\n",
      "total_losses:0.175\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.069\n",
      "fast_reg_loss:0.084\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:30: global_step:4560  current_step:4560\n",
      "speed: 0.354s, remaining training time: 00:03:12:56\n",
      "total_losses:0.609\n",
      "rpn_cls_loss:0.131\n",
      "rpn_reg_loss:0.025\n",
      "fast_cls_loss:0.169\n",
      "fast_reg_loss:0.284\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:37: global_step:4580  current_step:4580\n",
      "speed: 0.335s, remaining training time: 00:03:02:37\n",
      "total_losses:0.334\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.103\n",
      "fast_reg_loss:0.177\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:51: global_step:4620  current_step:4620\n",
      "speed: 0.331s, remaining training time: 00:03:00:17\n",
      "total_losses:0.331\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.133\n",
      "fast_reg_loss:0.171\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:00:57: global_step:4640  current_step:4640\n",
      "speed: 0.349s, remaining training time: 00:03:10:10\n",
      "total_losses:0.389\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.129\n",
      "fast_reg_loss:0.217\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:04: global_step:4660  current_step:4660\n",
      "speed: 0.339s, remaining training time: 00:03:04:35\n",
      "total_losses:0.404\n",
      "rpn_cls_loss:0.100\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.156\n",
      "fast_reg_loss:0.138\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:11: global_step:4680  current_step:4680\n",
      "speed: 0.325s, remaining training time: 00:02:56:27\n",
      "total_losses:0.317\n",
      "rpn_cls_loss:0.036\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.115\n",
      "fast_reg_loss:0.161\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:17: global_step:4700  current_step:4700\n",
      "speed: 0.364s, remaining training time: 00:03:17:59\n",
      "total_losses:0.717\n",
      "rpn_cls_loss:0.074\n",
      "rpn_reg_loss:0.022\n",
      "fast_cls_loss:0.237\n",
      "fast_reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:24: global_step:4720  current_step:4720\n",
      "speed: 0.338s, remaining training time: 00:03:03:43\n",
      "total_losses:0.270\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.089\n",
      "fast_reg_loss:0.131\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:31: global_step:4740  current_step:4740\n",
      "speed: 0.368s, remaining training time: 00:03:19:28\n",
      "total_losses:0.600\n",
      "rpn_cls_loss:0.060\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.226\n",
      "fast_reg_loss:0.301\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:37: global_step:4760  current_step:4760\n",
      "speed: 0.323s, remaining training time: 00:02:54:58\n",
      "total_losses:0.149\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.042\n",
      "fast_reg_loss:0.067\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:44: global_step:4780  current_step:4780\n",
      "speed: 0.360s, remaining training time: 00:03:14:59\n",
      "total_losses:0.513\n",
      "rpn_cls_loss:0.080\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.144\n",
      "fast_reg_loss:0.272\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:01:58: global_step:4820  current_step:4820\n",
      "speed: 0.330s, remaining training time: 00:02:58:43\n",
      "total_losses:0.216\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.061\n",
      "fast_reg_loss:0.120\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:04: global_step:4840  current_step:4840\n",
      "speed: 0.367s, remaining training time: 00:03:18:20\n",
      "total_losses:0.543\n",
      "rpn_cls_loss:0.095\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.173\n",
      "fast_reg_loss:0.261\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:02:12: global_step:4860  current_step:4860\n",
      "speed: 0.348s, remaining training time: 00:03:08:12\n",
      "total_losses:0.590\n",
      "rpn_cls_loss:0.102\n",
      "rpn_reg_loss:0.020\n",
      "fast_cls_loss:0.174\n",
      "fast_reg_loss:0.294\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:19: global_step:4880  current_step:4880\n",
      "speed: 0.343s, remaining training time: 00:03:05:11\n",
      "total_losses:0.431\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.160\n",
      "fast_reg_loss:0.233\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:25: global_step:4900  current_step:4900\n",
      "speed: 0.360s, remaining training time: 00:03:14:26\n",
      "total_losses:0.281\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.086\n",
      "fast_reg_loss:0.165\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:32: global_step:4920  current_step:4920\n",
      "speed: 0.326s, remaining training time: 00:02:55:56\n",
      "total_losses:0.411\n",
      "rpn_cls_loss:0.066\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.133\n",
      "fast_reg_loss:0.198\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:38: global_step:4940  current_step:4940\n",
      "speed: 0.317s, remaining training time: 00:02:50:44\n",
      "total_losses:0.173\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.050\n",
      "fast_reg_loss:0.090\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:45: global_step:4960  current_step:4960\n",
      "speed: 0.314s, remaining training time: 00:02:49:17\n",
      "total_losses:0.046\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.013\n",
      "fast_reg_loss:0.017\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:02:52: global_step:4980  current_step:4980\n",
      "speed: 0.312s, remaining training time: 00:02:47:53\n",
      "total_losses:0.192\n",
      "rpn_cls_loss:0.049\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.047\n",
      "fast_reg_loss:0.089\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:05: global_step:5020  current_step:5020\n",
      "speed: 0.327s, remaining training time: 00:02:55:58\n",
      "total_losses:0.266\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.101\n",
      "fast_reg_loss:0.126\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:11: global_step:5040  current_step:5040\n",
      "speed: 0.372s, remaining training time: 00:03:20:14\n",
      "total_losses:0.708\n",
      "rpn_cls_loss:0.065\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.226\n",
      "fast_reg_loss:0.401\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:18: global_step:5060  current_step:5060\n",
      "speed: 0.342s, remaining training time: 00:03:03:34\n",
      "total_losses:0.388\n",
      "rpn_cls_loss:0.078\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.099\n",
      "fast_reg_loss:0.201\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:25: global_step:5080  current_step:5080\n",
      "speed: 0.332s, remaining training time: 00:02:58:28\n",
      "total_losses:0.305\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.099\n",
      "fast_reg_loss:0.164\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:32: global_step:5100  current_step:5100\n",
      "speed: 0.344s, remaining training time: 00:03:04:46\n",
      "total_losses:0.384\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.146\n",
      "fast_reg_loss:0.188\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:38: global_step:5120  current_step:5120\n",
      "speed: 0.320s, remaining training time: 00:02:51:53\n",
      "total_losses:0.264\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.115\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:45: global_step:5140  current_step:5140\n",
      "speed: 0.347s, remaining training time: 00:03:05:43\n",
      "total_losses:0.401\n",
      "rpn_cls_loss:0.066\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.136\n",
      "fast_reg_loss:0.189\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:52: global_step:5160  current_step:5160\n",
      "speed: 0.326s, remaining training time: 00:02:54:53\n",
      "total_losses:0.432\n",
      "rpn_cls_loss:0.056\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.146\n",
      "fast_reg_loss:0.222\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:03:58: global_step:5180  current_step:5180\n",
      "speed: 0.338s, remaining training time: 00:03:01:11\n",
      "total_losses:0.122\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.038\n",
      "fast_reg_loss:0.061\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:04:12: global_step:5220  current_step:5220\n",
      "speed: 0.312s, remaining training time: 00:02:46:35\n",
      "total_losses:0.130\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.044\n",
      "fast_reg_loss:0.066\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:04:19: global_step:5240  current_step:5240\n",
      "speed: 0.346s, remaining training time: 00:03:04:45\n",
      "total_losses:0.403\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.126\n",
      "fast_reg_loss:0.213\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:04:26: global_step:5260  current_step:5260\n",
      "speed: 0.324s, remaining training time: 00:02:52:57\n",
      "total_losses:0.134\n",
      "rpn_cls_loss:0.036\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.041\n",
      "fast_reg_loss:0.053\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:04:33: global_step:5280  current_step:5280\n",
      "speed: 0.317s, remaining training time: 00:02:49:00\n",
      "total_losses:0.074\n",
      "rpn_cls_loss:0.019\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.024\n",
      "fast_reg_loss:0.030\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:04:39: global_step:5300  current_step:5300\n",
      "speed: 0.328s, remaining training time: 00:02:54:48\n",
      "total_losses:0.180\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.097\n",
      "fast_reg_loss:0.037\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:04:46: global_step:5320  current_step:5320\n",
      "speed: 0.365s, remaining training time: 00:03:14:28\n",
      "total_losses:0.417\n",
      "rpn_cls_loss:0.080\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.120\n",
      "fast_reg_loss:0.204\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:04:53: global_step:5340  current_step:5340\n",
      "speed: 0.339s, remaining training time: 00:03:00:47\n",
      "total_losses:0.390\n",
      "rpn_cls_loss:0.076\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.120\n",
      "fast_reg_loss:0.180\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:00: global_step:5360  current_step:5360\n",
      "speed: 0.332s, remaining training time: 00:02:56:51\n",
      "total_losses:0.300\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.108\n",
      "fast_reg_loss:0.158\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:06: global_step:5380  current_step:5380\n",
      "speed: 0.379s, remaining training time: 00:03:21:32\n",
      "total_losses:0.859\n",
      "rpn_cls_loss:0.100\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.373\n",
      "fast_reg_loss:0.371\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:20: global_step:5420  current_step:5420\n",
      "speed: 0.356s, remaining training time: 00:03:08:56\n",
      "total_losses:0.702\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.211\n",
      "fast_reg_loss:0.442\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:26: global_step:5440  current_step:5440\n",
      "speed: 0.358s, remaining training time: 00:03:10:00\n",
      "total_losses:0.538\n",
      "rpn_cls_loss:0.075\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.219\n",
      "fast_reg_loss:0.229\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:33: global_step:5460  current_step:5460\n",
      "speed: 0.320s, remaining training time: 00:02:50:01\n",
      "total_losses:0.378\n",
      "rpn_cls_loss:0.063\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.158\n",
      "fast_reg_loss:0.148\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:40: global_step:5480  current_step:5480\n",
      "speed: 0.341s, remaining training time: 00:03:00:58\n",
      "total_losses:0.296\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.097\n",
      "fast_reg_loss:0.140\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:46: global_step:5500  current_step:5500\n",
      "speed: 0.321s, remaining training time: 00:02:49:56\n",
      "total_losses:0.127\n",
      "rpn_cls_loss:0.020\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.043\n",
      "fast_reg_loss:0.062\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:05:53: global_step:5520  current_step:5520\n",
      "speed: 0.344s, remaining training time: 00:03:02:15\n",
      "total_losses:0.320\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.104\n",
      "fast_reg_loss:0.174\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:00: global_step:5540  current_step:5540\n",
      "speed: 0.330s, remaining training time: 00:02:54:49\n",
      "total_losses:0.196\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.072\n",
      "fast_reg_loss:0.073\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:06: global_step:5560  current_step:5560\n",
      "speed: 0.338s, remaining training time: 00:02:58:35\n",
      "total_losses:0.466\n",
      "rpn_cls_loss:0.061\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.141\n",
      "fast_reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:13: global_step:5580  current_step:5580\n",
      "speed: 0.314s, remaining training time: 00:02:46:07\n",
      "total_losses:0.110\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.030\n",
      "fast_reg_loss:0.044\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:06:27: global_step:5620  current_step:5620\n",
      "speed: 0.318s, remaining training time: 00:02:48:06\n",
      "total_losses:0.248\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.091\n",
      "fast_reg_loss:0.105\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:34: global_step:5640  current_step:5640\n",
      "speed: 0.373s, remaining training time: 00:03:17:00\n",
      "total_losses:0.507\n",
      "rpn_cls_loss:0.072\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.171\n",
      "fast_reg_loss:0.248\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:41: global_step:5660  current_step:5660\n",
      "speed: 0.329s, remaining training time: 00:02:53:20\n",
      "total_losses:0.169\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.059\n",
      "fast_reg_loss:0.071\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:47: global_step:5680  current_step:5680\n",
      "speed: 0.322s, remaining training time: 00:02:49:43\n",
      "total_losses:0.214\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.072\n",
      "fast_reg_loss:0.091\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:06:54: global_step:5700  current_step:5700\n",
      "speed: 0.372s, remaining training time: 00:03:16:09\n",
      "total_losses:0.586\n",
      "rpn_cls_loss:0.114\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.172\n",
      "fast_reg_loss:0.281\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:01: global_step:5720  current_step:5720\n",
      "speed: 0.354s, remaining training time: 00:03:06:11\n",
      "total_losses:0.320\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.133\n",
      "fast_reg_loss:0.133\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:07: global_step:5740  current_step:5740\n",
      "speed: 0.314s, remaining training time: 00:02:45:03\n",
      "total_losses:0.143\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.062\n",
      "fast_reg_loss:0.060\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:14: global_step:5760  current_step:5760\n",
      "speed: 0.332s, remaining training time: 00:02:54:27\n",
      "total_losses:0.236\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.067\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:21: global_step:5780  current_step:5780\n",
      "speed: 0.321s, remaining training time: 00:02:48:40\n",
      "total_losses:0.155\n",
      "rpn_cls_loss:0.067\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.033\n",
      "fast_reg_loss:0.048\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:34: global_step:5820  current_step:5820\n",
      "speed: 0.328s, remaining training time: 00:02:51:54\n",
      "total_losses:0.210\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.088\n",
      "fast_reg_loss:0.092\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:41: global_step:5840  current_step:5840\n",
      "speed: 0.329s, remaining training time: 00:02:52:20\n",
      "total_losses:0.248\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.096\n",
      "fast_reg_loss:0.116\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:47: global_step:5860  current_step:5860\n",
      "speed: 0.322s, remaining training time: 00:02:48:55\n",
      "total_losses:0.510\n",
      "rpn_cls_loss:0.065\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.187\n",
      "fast_reg_loss:0.249\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:07:54: global_step:5880  current_step:5880\n",
      "speed: 0.356s, remaining training time: 00:03:06:34\n",
      "total_losses:0.398\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.129\n",
      "fast_reg_loss:0.200\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:01: global_step:5900  current_step:5900\n",
      "speed: 0.306s, remaining training time: 00:02:40:23\n",
      "total_losses:0.242\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.126\n",
      "fast_reg_loss:0.059\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:07: global_step:5920  current_step:5920\n",
      "speed: 0.340s, remaining training time: 00:02:57:41\n",
      "total_losses:0.374\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.131\n",
      "fast_reg_loss:0.201\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:14: global_step:5940  current_step:5940\n",
      "speed: 0.315s, remaining training time: 00:02:44:23\n",
      "total_losses:0.158\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.050\n",
      "fast_reg_loss:0.077\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:21: global_step:5960  current_step:5960\n",
      "speed: 0.372s, remaining training time: 00:03:14:26\n",
      "total_losses:0.694\n",
      "rpn_cls_loss:0.102\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.190\n",
      "fast_reg_loss:0.382\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:08:28: global_step:5980  current_step:5980\n",
      "speed: 0.362s, remaining training time: 00:03:09:09\n",
      "total_losses:0.347\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.110\n",
      "fast_reg_loss:0.185\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:42: global_step:6020  current_step:6020\n",
      "speed: 0.307s, remaining training time: 00:02:39:57\n",
      "total_losses:0.220\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.075\n",
      "fast_reg_loss:0.082\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:49: global_step:6040  current_step:6040\n",
      "speed: 0.374s, remaining training time: 00:03:14:42\n",
      "total_losses:0.506\n",
      "rpn_cls_loss:0.082\n",
      "rpn_reg_loss:0.024\n",
      "fast_cls_loss:0.146\n",
      "fast_reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:08:55: global_step:6060  current_step:6060\n",
      "speed: 0.306s, remaining training time: 00:02:39:11\n",
      "total_losses:0.100\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.033\n",
      "fast_reg_loss:0.039\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:02: global_step:6080  current_step:6080\n",
      "speed: 0.311s, remaining training time: 00:02:42:00\n",
      "total_losses:0.375\n",
      "rpn_cls_loss:0.066\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.185\n",
      "fast_reg_loss:0.119\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:09: global_step:6100  current_step:6100\n",
      "speed: 0.331s, remaining training time: 00:02:52:02\n",
      "total_losses:0.246\n",
      "rpn_cls_loss:0.082\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.059\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:16: global_step:6120  current_step:6120\n",
      "speed: 0.331s, remaining training time: 00:02:51:46\n",
      "total_losses:0.115\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.035\n",
      "fast_reg_loss:0.050\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:23: global_step:6140  current_step:6140\n",
      "speed: 0.308s, remaining training time: 00:02:39:48\n",
      "total_losses:0.324\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.141\n",
      "fast_reg_loss:0.126\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:29: global_step:6160  current_step:6160\n",
      "speed: 0.321s, remaining training time: 00:02:46:39\n",
      "total_losses:0.219\n",
      "rpn_cls_loss:0.055\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.057\n",
      "fast_reg_loss:0.104\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:36: global_step:6180  current_step:6180\n",
      "speed: 0.318s, remaining training time: 00:02:44:53\n",
      "total_losses:0.087\n",
      "rpn_cls_loss:0.017\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.029\n",
      "fast_reg_loss:0.039\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:49: global_step:6220  current_step:6220\n",
      "speed: 0.334s, remaining training time: 00:02:52:46\n",
      "total_losses:0.323\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.138\n",
      "fast_reg_loss:0.141\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:09:56: global_step:6240  current_step:6240\n",
      "speed: 0.328s, remaining training time: 00:02:49:51\n",
      "total_losses:0.314\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.091\n",
      "fast_reg_loss:0.173\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:02: global_step:6260  current_step:6260\n",
      "speed: 0.314s, remaining training time: 00:02:42:40\n",
      "total_losses:0.339\n",
      "rpn_cls_loss:0.058\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.118\n",
      "fast_reg_loss:0.153\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:09: global_step:6280  current_step:6280\n",
      "speed: 0.362s, remaining training time: 00:03:06:57\n",
      "total_losses:0.391\n",
      "rpn_cls_loss:0.078\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.119\n",
      "fast_reg_loss:0.183\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:16: global_step:6300  current_step:6300\n",
      "speed: 0.320s, remaining training time: 00:02:45:29\n",
      "total_losses:0.138\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.038\n",
      "fast_reg_loss:0.058\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:22: global_step:6320  current_step:6320\n",
      "speed: 0.331s, remaining training time: 00:02:50:57\n",
      "total_losses:0.161\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.062\n",
      "fast_reg_loss:0.070\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:29: global_step:6340  current_step:6340\n",
      "speed: 0.352s, remaining training time: 00:03:01:23\n",
      "total_losses:0.610\n",
      "rpn_cls_loss:0.091\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:0.186\n",
      "fast_reg_loss:0.315\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:10:37: global_step:6360  current_step:6360\n",
      "speed: 0.334s, remaining training time: 00:02:52:29\n",
      "total_losses:0.287\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.154\n",
      "fast_reg_loss:0.079\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:43: global_step:6380  current_step:6380\n",
      "speed: 0.342s, remaining training time: 00:02:56:25\n",
      "total_losses:0.402\n",
      "rpn_cls_loss:0.077\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.135\n",
      "fast_reg_loss:0.175\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:10:57: global_step:6420  current_step:6420\n",
      "speed: 0.336s, remaining training time: 00:02:53:00\n",
      "total_losses:0.464\n",
      "rpn_cls_loss:0.060\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.136\n",
      "fast_reg_loss:0.260\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:03: global_step:6440  current_step:6440\n",
      "speed: 0.353s, remaining training time: 00:03:01:36\n",
      "total_losses:0.652\n",
      "rpn_cls_loss:0.136\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.169\n",
      "fast_reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:10: global_step:6460  current_step:6460\n",
      "speed: 0.323s, remaining training time: 00:02:46:02\n",
      "total_losses:0.094\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.030\n",
      "fast_reg_loss:0.027\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:17: global_step:6480  current_step:6480\n",
      "speed: 0.342s, remaining training time: 00:02:55:25\n",
      "total_losses:0.573\n",
      "rpn_cls_loss:0.121\n",
      "rpn_reg_loss:0.021\n",
      "fast_cls_loss:0.171\n",
      "fast_reg_loss:0.260\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:23: global_step:6500  current_step:6500\n",
      "speed: 0.364s, remaining training time: 00:03:06:45\n",
      "total_losses:0.397\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.125\n",
      "fast_reg_loss:0.215\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:30: global_step:6520  current_step:6520\n",
      "speed: 0.316s, remaining training time: 00:02:42:04\n",
      "total_losses:0.210\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.063\n",
      "fast_reg_loss:0.109\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:36: global_step:6540  current_step:6540\n",
      "speed: 0.332s, remaining training time: 00:02:50:11\n",
      "total_losses:0.389\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.121\n",
      "fast_reg_loss:0.205\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:43: global_step:6560  current_step:6560\n",
      "speed: 0.316s, remaining training time: 00:02:41:59\n",
      "total_losses:0.203\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.093\n",
      "fast_reg_loss:0.082\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:11:50: global_step:6580  current_step:6580\n",
      "speed: 0.358s, remaining training time: 00:03:03:32\n",
      "total_losses:0.385\n",
      "rpn_cls_loss:0.061\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.099\n",
      "fast_reg_loss:0.212\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:03: global_step:6620  current_step:6620\n",
      "speed: 0.324s, remaining training time: 00:02:45:29\n",
      "total_losses:0.173\n",
      "rpn_cls_loss:0.053\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.049\n",
      "fast_reg_loss:0.068\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:10: global_step:6640  current_step:6640\n",
      "speed: 0.364s, remaining training time: 00:03:06:12\n",
      "total_losses:0.319\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.102\n",
      "fast_reg_loss:0.162\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:17: global_step:6660  current_step:6660\n",
      "speed: 0.320s, remaining training time: 00:02:43:28\n",
      "total_losses:0.176\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.056\n",
      "fast_reg_loss:0.081\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:24: global_step:6680  current_step:6680\n",
      "speed: 0.312s, remaining training time: 00:02:39:13\n",
      "total_losses:0.216\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.077\n",
      "fast_reg_loss:0.101\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:30: global_step:6700  current_step:6700\n",
      "speed: 0.374s, remaining training time: 00:03:10:34\n",
      "total_losses:0.495\n",
      "rpn_cls_loss:0.101\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.167\n",
      "fast_reg_loss:0.214\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:12:38: global_step:6720  current_step:6720\n",
      "speed: 0.342s, remaining training time: 00:02:54:09\n",
      "total_losses:0.317\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.090\n",
      "fast_reg_loss:0.184\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:44: global_step:6740  current_step:6740\n",
      "speed: 0.331s, remaining training time: 00:02:48:44\n",
      "total_losses:0.540\n",
      "rpn_cls_loss:0.071\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.186\n",
      "fast_reg_loss:0.268\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:51: global_step:6760  current_step:6760\n",
      "speed: 0.314s, remaining training time: 00:02:39:37\n",
      "total_losses:0.208\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.043\n",
      "fast_reg_loss:0.120\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:12:58: global_step:6780  current_step:6780\n",
      "speed: 0.361s, remaining training time: 00:03:03:41\n",
      "total_losses:0.405\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.118\n",
      "fast_reg_loss:0.228\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:11: global_step:6820  current_step:6820\n",
      "speed: 0.342s, remaining training time: 00:02:53:41\n",
      "total_losses:0.457\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.170\n",
      "fast_reg_loss:0.232\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:18: global_step:6840  current_step:6840\n",
      "speed: 0.308s, remaining training time: 00:02:36:33\n",
      "total_losses:0.105\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.026\n",
      "fast_reg_loss:0.056\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:25: global_step:6860  current_step:6860\n",
      "speed: 0.325s, remaining training time: 00:02:44:59\n",
      "total_losses:0.209\n",
      "rpn_cls_loss:0.078\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.039\n",
      "fast_reg_loss:0.080\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:31: global_step:6880  current_step:6880\n",
      "speed: 0.332s, remaining training time: 00:02:48:25\n",
      "total_losses:0.230\n",
      "rpn_cls_loss:0.062\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.063\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:38: global_step:6900  current_step:6900\n",
      "speed: 0.340s, remaining training time: 00:02:52:07\n",
      "total_losses:0.359\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.121\n",
      "fast_reg_loss:0.199\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:45: global_step:6920  current_step:6920\n",
      "speed: 0.363s, remaining training time: 00:03:03:55\n",
      "total_losses:0.510\n",
      "rpn_cls_loss:0.080\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:0.190\n",
      "fast_reg_loss:0.222\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:51: global_step:6940  current_step:6940\n",
      "speed: 0.362s, remaining training time: 00:03:03:16\n",
      "total_losses:0.494\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.160\n",
      "fast_reg_loss:0.266\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:13:58: global_step:6960  current_step:6960\n",
      "speed: 0.316s, remaining training time: 00:02:39:51\n",
      "total_losses:0.211\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.075\n",
      "fast_reg_loss:0.088\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:05: global_step:6980  current_step:6980\n",
      "speed: 0.321s, remaining training time: 00:02:42:24\n",
      "total_losses:0.153\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.041\n",
      "fast_reg_loss:0.084\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:18: global_step:7020  current_step:7020\n",
      "speed: 0.339s, remaining training time: 00:02:51:07\n",
      "total_losses:0.445\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.175\n",
      "fast_reg_loss:0.232\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:25: global_step:7040  current_step:7040\n",
      "speed: 0.328s, remaining training time: 00:02:45:38\n",
      "total_losses:0.335\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.120\n",
      "fast_reg_loss:0.181\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:31: global_step:7060  current_step:7060\n",
      "speed: 0.345s, remaining training time: 00:02:53:41\n",
      "total_losses:0.347\n",
      "rpn_cls_loss:0.036\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.117\n",
      "fast_reg_loss:0.181\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:38: global_step:7080  current_step:7080\n",
      "speed: 0.322s, remaining training time: 00:02:42:14\n",
      "total_losses:0.131\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.031\n",
      "fast_reg_loss:0.076\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:14:46: global_step:7100  current_step:7100\n",
      "speed: 0.333s, remaining training time: 00:02:47:39\n",
      "total_losses:0.074\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.017\n",
      "fast_reg_loss:0.029\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:52: global_step:7120  current_step:7120\n",
      "speed: 0.362s, remaining training time: 00:03:01:58\n",
      "total_losses:0.516\n",
      "rpn_cls_loss:0.095\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.193\n",
      "fast_reg_loss:0.212\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:14:59: global_step:7140  current_step:7140\n",
      "speed: 0.320s, remaining training time: 00:02:40:46\n",
      "total_losses:0.079\n",
      "rpn_cls_loss:0.011\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.035\n",
      "fast_reg_loss:0.032\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:05: global_step:7160  current_step:7160\n",
      "speed: 0.339s, remaining training time: 00:02:50:27\n",
      "total_losses:0.554\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.179\n",
      "fast_reg_loss:0.296\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:12: global_step:7180  current_step:7180\n",
      "speed: 0.333s, remaining training time: 00:02:47:14\n",
      "total_losses:0.130\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.050\n",
      "fast_reg_loss:0.051\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:26: global_step:7220  current_step:7220\n",
      "speed: 0.325s, remaining training time: 00:02:42:49\n",
      "total_losses:0.186\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.063\n",
      "fast_reg_loss:0.082\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:32: global_step:7240  current_step:7240\n",
      "speed: 0.320s, remaining training time: 00:02:40:22\n",
      "total_losses:0.237\n",
      "rpn_cls_loss:0.061\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.125\n",
      "fast_reg_loss:0.046\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:39: global_step:7260  current_step:7260\n",
      "speed: 0.339s, remaining training time: 00:02:49:51\n",
      "total_losses:0.426\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.146\n",
      "fast_reg_loss:0.229\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:46: global_step:7280  current_step:7280\n",
      "speed: 0.318s, remaining training time: 00:02:39:16\n",
      "total_losses:0.393\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.152\n",
      "fast_reg_loss:0.212\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:52: global_step:7300  current_step:7300\n",
      "speed: 0.317s, remaining training time: 00:02:38:21\n",
      "total_losses:0.091\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.048\n",
      "fast_reg_loss:0.026\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:15:59: global_step:7320  current_step:7320\n",
      "speed: 0.355s, remaining training time: 00:02:57:09\n",
      "total_losses:0.442\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.142\n",
      "fast_reg_loss:0.247\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:16:06: global_step:7340  current_step:7340\n",
      "speed: 0.327s, remaining training time: 00:02:43:16\n",
      "total_losses:0.173\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.057\n",
      "fast_reg_loss:0.087\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:16:12: global_step:7360  current_step:7360\n",
      "speed: 0.355s, remaining training time: 00:02:57:03\n",
      "total_losses:0.557\n",
      "rpn_cls_loss:0.063\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.178\n",
      "fast_reg_loss:0.303\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:16:19: global_step:7380  current_step:7380\n",
      "speed: 0.352s, remaining training time: 00:02:55:33\n",
      "total_losses:0.272\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.077\n",
      "fast_reg_loss:0.153\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:16:32: global_step:7420  current_step:7420\n",
      "speed: 0.314s, remaining training time: 00:02:36:32\n",
      "total_losses:0.106\n",
      "rpn_cls_loss:0.010\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.033\n",
      "fast_reg_loss:0.059\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:16:39: global_step:7440  current_step:7440\n",
      "speed: 0.358s, remaining training time: 00:02:58:01\n",
      "total_losses:0.472\n",
      "rpn_cls_loss:0.069\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.137\n",
      "fast_reg_loss:0.253\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:16:46: global_step:7460  current_step:7460\n",
      "speed: 0.346s, remaining training time: 00:02:52:10\n",
      "total_losses:0.291\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.108\n",
      "fast_reg_loss:0.135\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:16:53: global_step:7480  current_step:7480\n",
      "speed: 0.334s, remaining training time: 00:02:45:50\n",
      "total_losses:0.233\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.074\n",
      "fast_reg_loss:0.105\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:00: global_step:7500  current_step:7500\n",
      "speed: 0.344s, remaining training time: 00:02:50:40\n",
      "total_losses:0.244\n",
      "rpn_cls_loss:0.081\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.084\n",
      "fast_reg_loss:0.073\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:07: global_step:7520  current_step:7520\n",
      "speed: 0.326s, remaining training time: 00:02:41:34\n",
      "total_losses:0.281\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.113\n",
      "fast_reg_loss:0.138\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:13: global_step:7540  current_step:7540\n",
      "speed: 0.343s, remaining training time: 00:02:49:55\n",
      "total_losses:0.615\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.200\n",
      "fast_reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:20: global_step:7560  current_step:7560\n",
      "speed: 0.328s, remaining training time: 00:02:42:27\n",
      "total_losses:0.153\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.064\n",
      "fast_reg_loss:0.065\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:27: global_step:7580  current_step:7580\n",
      "speed: 0.332s, remaining training time: 00:02:44:38\n",
      "total_losses:0.260\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.082\n",
      "fast_reg_loss:0.138\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:40: global_step:7620  current_step:7620\n",
      "speed: 0.352s, remaining training time: 00:02:53:59\n",
      "total_losses:0.369\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.137\n",
      "fast_reg_loss:0.166\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:47: global_step:7640  current_step:7640\n",
      "speed: 0.356s, remaining training time: 00:02:55:59\n",
      "total_losses:0.544\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.171\n",
      "fast_reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:17:53: global_step:7660  current_step:7660\n",
      "speed: 0.338s, remaining training time: 00:02:47:10\n",
      "total_losses:0.420\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.150\n",
      "fast_reg_loss:0.217\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:00: global_step:7680  current_step:7680\n",
      "speed: 0.312s, remaining training time: 00:02:34:01\n",
      "total_losses:0.377\n",
      "rpn_cls_loss:0.070\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.124\n",
      "fast_reg_loss:0.174\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:07: global_step:7700  current_step:7700\n",
      "speed: 0.306s, remaining training time: 00:02:30:57\n",
      "total_losses:0.148\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.054\n",
      "fast_reg_loss:0.063\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:13: global_step:7720  current_step:7720\n",
      "speed: 0.343s, remaining training time: 00:02:49:07\n",
      "total_losses:0.276\n",
      "rpn_cls_loss:0.058\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.087\n",
      "fast_reg_loss:0.123\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:20: global_step:7740  current_step:7740\n",
      "speed: 0.343s, remaining training time: 00:02:49:13\n",
      "total_losses:0.504\n",
      "rpn_cls_loss:0.118\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.124\n",
      "fast_reg_loss:0.246\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:27: global_step:7760  current_step:7760\n",
      "speed: 0.325s, remaining training time: 00:02:40:01\n",
      "total_losses:0.213\n",
      "rpn_cls_loss:0.049\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.060\n",
      "fast_reg_loss:0.098\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:33: global_step:7780  current_step:7780\n",
      "speed: 0.331s, remaining training time: 00:02:42:37\n",
      "total_losses:0.250\n",
      "rpn_cls_loss:0.055\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.087\n",
      "fast_reg_loss:0.102\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:18:47: global_step:7820  current_step:7820\n",
      "speed: 0.327s, remaining training time: 00:02:40:30\n",
      "total_losses:0.216\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.083\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:18:54: global_step:7840  current_step:7840\n",
      "speed: 0.339s, remaining training time: 00:02:46:24\n",
      "total_losses:0.144\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.044\n",
      "fast_reg_loss:0.057\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:01: global_step:7860  current_step:7860\n",
      "speed: 0.309s, remaining training time: 00:02:31:47\n",
      "total_losses:0.169\n",
      "rpn_cls_loss:0.067\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.035\n",
      "fast_reg_loss:0.059\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:08: global_step:7880  current_step:7880\n",
      "speed: 0.317s, remaining training time: 00:02:35:32\n",
      "total_losses:0.224\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.054\n",
      "fast_reg_loss:0.117\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:14: global_step:7900  current_step:7900\n",
      "speed: 0.325s, remaining training time: 00:02:39:04\n",
      "total_losses:0.156\n",
      "rpn_cls_loss:0.013\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.038\n",
      "fast_reg_loss:0.102\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:21: global_step:7920  current_step:7920\n",
      "speed: 0.327s, remaining training time: 00:02:40:06\n",
      "total_losses:0.201\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.054\n",
      "fast_reg_loss:0.090\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:28: global_step:7940  current_step:7940\n",
      "speed: 0.341s, remaining training time: 00:02:46:41\n",
      "total_losses:0.611\n",
      "rpn_cls_loss:0.110\n",
      "rpn_reg_loss:0.021\n",
      "fast_cls_loss:0.175\n",
      "fast_reg_loss:0.305\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:34: global_step:7960  current_step:7960\n",
      "speed: 0.326s, remaining training time: 00:02:39:19\n",
      "total_losses:0.118\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.038\n",
      "fast_reg_loss:0.033\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:41: global_step:7980  current_step:7980\n",
      "speed: 0.367s, remaining training time: 00:02:59:11\n",
      "total_losses:0.500\n",
      "rpn_cls_loss:0.086\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.141\n",
      "fast_reg_loss:0.257\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:19:54: global_step:8020  current_step:8020\n",
      "speed: 0.338s, remaining training time: 00:02:45:04\n",
      "total_losses:0.321\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.100\n",
      "fast_reg_loss:0.168\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:01: global_step:8040  current_step:8040\n",
      "speed: 0.326s, remaining training time: 00:02:39:10\n",
      "total_losses:0.335\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.130\n",
      "fast_reg_loss:0.185\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:08: global_step:8060  current_step:8060\n",
      "speed: 0.330s, remaining training time: 00:02:40:50\n",
      "total_losses:0.187\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.056\n",
      "fast_reg_loss:0.094\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:14: global_step:8080  current_step:8080\n",
      "speed: 0.320s, remaining training time: 00:02:35:55\n",
      "total_losses:0.321\n",
      "rpn_cls_loss:0.121\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.093\n",
      "fast_reg_loss:0.095\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:21: global_step:8100  current_step:8100\n",
      "speed: 0.339s, remaining training time: 00:02:45:03\n",
      "total_losses:0.397\n",
      "rpn_cls_loss:0.053\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.127\n",
      "fast_reg_loss:0.209\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:27: global_step:8120  current_step:8120\n",
      "speed: 0.343s, remaining training time: 00:02:46:39\n",
      "total_losses:0.320\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.082\n",
      "fast_reg_loss:0.188\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:34: global_step:8140  current_step:8140\n",
      "speed: 0.369s, remaining training time: 00:02:59:18\n",
      "total_losses:0.741\n",
      "rpn_cls_loss:0.176\n",
      "rpn_reg_loss:0.025\n",
      "fast_cls_loss:0.225\n",
      "fast_reg_loss:0.316\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:41: global_step:8160  current_step:8160\n",
      "speed: 0.319s, remaining training time: 00:02:34:52\n",
      "total_losses:0.149\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.066\n",
      "fast_reg_loss:0.047\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:20:47: global_step:8180  current_step:8180\n",
      "speed: 0.317s, remaining training time: 00:02:33:51\n",
      "total_losses:0.282\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.124\n",
      "fast_reg_loss:0.110\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:21:02: global_step:8220  current_step:8220\n",
      "speed: 0.355s, remaining training time: 00:02:52:07\n",
      "total_losses:0.494\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.017\n",
      "fast_cls_loss:0.145\n",
      "fast_reg_loss:0.268\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:08: global_step:8240  current_step:8240\n",
      "speed: 0.311s, remaining training time: 00:02:30:33\n",
      "total_losses:0.167\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.091\n",
      "fast_reg_loss:0.040\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:15: global_step:8260  current_step:8260\n",
      "speed: 0.311s, remaining training time: 00:02:30:25\n",
      "total_losses:0.330\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.117\n",
      "fast_reg_loss:0.144\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:21: global_step:8280  current_step:8280\n",
      "speed: 0.325s, remaining training time: 00:02:37:14\n",
      "total_losses:0.198\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.073\n",
      "fast_reg_loss:0.104\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:28: global_step:8300  current_step:8300\n",
      "speed: 0.369s, remaining training time: 00:02:58:14\n",
      "total_losses:0.319\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.109\n",
      "fast_reg_loss:0.158\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:35: global_step:8320  current_step:8320\n",
      "speed: 0.333s, remaining training time: 00:02:40:53\n",
      "total_losses:0.364\n",
      "rpn_cls_loss:0.024\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.130\n",
      "fast_reg_loss:0.198\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:41: global_step:8340  current_step:8340\n",
      "speed: 0.374s, remaining training time: 00:03:00:23\n",
      "total_losses:0.490\n",
      "rpn_cls_loss:0.122\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:0.159\n",
      "fast_reg_loss:0.190\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:48: global_step:8360  current_step:8360\n",
      "speed: 0.333s, remaining training time: 00:02:40:43\n",
      "total_losses:0.203\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.069\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:21:55: global_step:8380  current_step:8380\n",
      "speed: 0.328s, remaining training time: 00:02:38:13\n",
      "total_losses:0.169\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.060\n",
      "fast_reg_loss:0.081\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:08: global_step:8420  current_step:8420\n",
      "speed: 0.322s, remaining training time: 00:02:35:04\n",
      "total_losses:0.170\n",
      "rpn_cls_loss:0.055\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.037\n",
      "fast_reg_loss:0.074\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:15: global_step:8440  current_step:8440\n",
      "speed: 0.325s, remaining training time: 00:02:36:23\n",
      "total_losses:0.083\n",
      "rpn_cls_loss:0.020\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.018\n",
      "fast_reg_loss:0.042\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:22: global_step:8460  current_step:8460\n",
      "speed: 0.321s, remaining training time: 00:02:34:29\n",
      "total_losses:0.144\n",
      "rpn_cls_loss:0.036\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.029\n",
      "fast_reg_loss:0.077\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:29: global_step:8480  current_step:8480\n",
      "speed: 0.329s, remaining training time: 00:02:38:07\n",
      "total_losses:0.278\n",
      "rpn_cls_loss:0.055\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.084\n",
      "fast_reg_loss:0.134\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:35: global_step:8500  current_step:8500\n",
      "speed: 0.335s, remaining training time: 00:02:40:40\n",
      "total_losses:0.285\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.100\n",
      "fast_reg_loss:0.146\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:42: global_step:8520  current_step:8520\n",
      "speed: 0.306s, remaining training time: 00:02:26:42\n",
      "total_losses:0.151\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.042\n",
      "fast_reg_loss:0.061\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:49: global_step:8540  current_step:8540\n",
      "speed: 0.345s, remaining training time: 00:02:45:35\n",
      "total_losses:0.302\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.097\n",
      "fast_reg_loss:0.150\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:22:55: global_step:8560  current_step:8560\n",
      "speed: 0.327s, remaining training time: 00:02:36:31\n",
      "total_losses:0.237\n",
      "rpn_cls_loss:0.021\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.072\n",
      "fast_reg_loss:0.140\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:23:03: global_step:8580  current_step:8580\n",
      "speed: 0.325s, remaining training time: 00:02:35:41\n",
      "total_losses:0.253\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.108\n",
      "fast_reg_loss:0.107\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:16: global_step:8620  current_step:8620\n",
      "speed: 0.318s, remaining training time: 00:02:32:01\n",
      "total_losses:0.141\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.041\n",
      "fast_reg_loss:0.065\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:23: global_step:8640  current_step:8640\n",
      "speed: 0.312s, remaining training time: 00:02:28:49\n",
      "total_losses:0.109\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.033\n",
      "fast_reg_loss:0.047\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:30: global_step:8660  current_step:8660\n",
      "speed: 0.340s, remaining training time: 00:02:42:19\n",
      "total_losses:0.494\n",
      "rpn_cls_loss:0.061\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.193\n",
      "fast_reg_loss:0.226\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:36: global_step:8680  current_step:8680\n",
      "speed: 0.337s, remaining training time: 00:02:40:51\n",
      "total_losses:0.675\n",
      "rpn_cls_loss:0.134\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.199\n",
      "fast_reg_loss:0.326\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:43: global_step:8700  current_step:8700\n",
      "speed: 0.318s, remaining training time: 00:02:31:32\n",
      "total_losses:0.256\n",
      "rpn_cls_loss:0.080\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.083\n",
      "fast_reg_loss:0.081\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:50: global_step:8720  current_step:8720\n",
      "speed: 0.318s, remaining training time: 00:02:31:39\n",
      "total_losses:0.159\n",
      "rpn_cls_loss:0.038\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.037\n",
      "fast_reg_loss:0.083\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:23:56: global_step:8740  current_step:8740\n",
      "speed: 0.344s, remaining training time: 00:02:43:46\n",
      "total_losses:0.571\n",
      "rpn_cls_loss:0.073\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.146\n",
      "fast_reg_loss:0.334\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:03: global_step:8760  current_step:8760\n",
      "speed: 0.363s, remaining training time: 00:02:52:25\n",
      "total_losses:0.709\n",
      "rpn_cls_loss:0.161\n",
      "rpn_reg_loss:0.019\n",
      "fast_cls_loss:0.206\n",
      "fast_reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:10: global_step:8780  current_step:8780\n",
      "speed: 0.350s, remaining training time: 00:02:46:22\n",
      "total_losses:0.500\n",
      "rpn_cls_loss:0.124\n",
      "rpn_reg_loss:0.023\n",
      "fast_cls_loss:0.115\n",
      "fast_reg_loss:0.239\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:23: global_step:8820  current_step:8820\n",
      "speed: 0.359s, remaining training time: 00:02:50:18\n",
      "total_losses:0.449\n",
      "rpn_cls_loss:0.040\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.134\n",
      "fast_reg_loss:0.262\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:30: global_step:8840  current_step:8840\n",
      "speed: 0.328s, remaining training time: 00:02:35:39\n",
      "total_losses:0.097\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.034\n",
      "fast_reg_loss:0.035\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:36: global_step:8860  current_step:8860\n",
      "speed: 0.314s, remaining training time: 00:02:28:42\n",
      "total_losses:0.137\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.036\n",
      "fast_reg_loss:0.064\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:43: global_step:8880  current_step:8880\n",
      "speed: 0.316s, remaining training time: 00:02:29:41\n",
      "total_losses:0.184\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.061\n",
      "fast_reg_loss:0.086\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:50: global_step:8900  current_step:8900\n",
      "speed: 0.315s, remaining training time: 00:02:28:55\n",
      "total_losses:0.210\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.066\n",
      "fast_reg_loss:0.091\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:24:56: global_step:8920  current_step:8920\n",
      "speed: 0.376s, remaining training time: 00:02:57:58\n",
      "total_losses:0.547\n",
      "rpn_cls_loss:0.141\n",
      "rpn_reg_loss:0.024\n",
      "fast_cls_loss:0.147\n",
      "fast_reg_loss:0.235\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:03: global_step:8940  current_step:8940\n",
      "speed: 0.327s, remaining training time: 00:02:34:31\n",
      "total_losses:0.200\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.069\n",
      "fast_reg_loss:0.102\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:25:10: global_step:8960  current_step:8960\n",
      "speed: 0.326s, remaining training time: 00:02:33:46\n",
      "total_losses:0.245\n",
      "rpn_cls_loss:0.088\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.046\n",
      "fast_reg_loss:0.097\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:17: global_step:8980  current_step:8980\n",
      "speed: 0.329s, remaining training time: 00:02:35:29\n",
      "total_losses:0.218\n",
      "rpn_cls_loss:0.027\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.076\n",
      "fast_reg_loss:0.111\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:31: global_step:9020  current_step:9020\n",
      "speed: 0.365s, remaining training time: 00:02:51:51\n",
      "total_losses:0.506\n",
      "rpn_cls_loss:0.131\n",
      "rpn_reg_loss:0.020\n",
      "fast_cls_loss:0.165\n",
      "fast_reg_loss:0.190\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:37: global_step:9040  current_step:9040\n",
      "speed: 0.330s, remaining training time: 00:02:35:20\n",
      "total_losses:0.191\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.053\n",
      "fast_reg_loss:0.086\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:44: global_step:9060  current_step:9060\n",
      "speed: 0.363s, remaining training time: 00:02:50:46\n",
      "total_losses:0.442\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.150\n",
      "fast_reg_loss:0.236\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:51: global_step:9080  current_step:9080\n",
      "speed: 0.325s, remaining training time: 00:02:32:43\n",
      "total_losses:0.165\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.045\n",
      "fast_reg_loss:0.092\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:25:58: global_step:9100  current_step:9100\n",
      "speed: 0.331s, remaining training time: 00:02:35:27\n",
      "total_losses:0.341\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.107\n",
      "fast_reg_loss:0.193\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:04: global_step:9120  current_step:9120\n",
      "speed: 0.355s, remaining training time: 00:02:46:41\n",
      "total_losses:0.378\n",
      "rpn_cls_loss:0.062\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.106\n",
      "fast_reg_loss:0.198\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:11: global_step:9140  current_step:9140\n",
      "speed: 0.327s, remaining training time: 00:02:33:40\n",
      "total_losses:0.348\n",
      "rpn_cls_loss:0.048\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.098\n",
      "fast_reg_loss:0.191\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:18: global_step:9160  current_step:9160\n",
      "speed: 0.318s, remaining training time: 00:02:28:57\n",
      "total_losses:0.081\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.020\n",
      "fast_reg_loss:0.032\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:24: global_step:9180  current_step:9180\n",
      "speed: 0.369s, remaining training time: 00:02:53:07\n",
      "total_losses:0.514\n",
      "rpn_cls_loss:0.090\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.157\n",
      "fast_reg_loss:0.251\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:38: global_step:9220  current_step:9220\n",
      "speed: 0.362s, remaining training time: 00:02:49:29\n",
      "total_losses:0.639\n",
      "rpn_cls_loss:0.065\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.271\n",
      "fast_reg_loss:0.288\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:44: global_step:9240  current_step:9240\n",
      "speed: 0.313s, remaining training time: 00:02:26:17\n",
      "total_losses:0.205\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.074\n",
      "fast_reg_loss:0.095\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:51: global_step:9260  current_step:9260\n",
      "speed: 0.325s, remaining training time: 00:02:31:57\n",
      "total_losses:0.175\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.067\n",
      "fast_reg_loss:0.076\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:26:58: global_step:9280  current_step:9280\n",
      "speed: 0.328s, remaining training time: 00:02:33:05\n",
      "total_losses:0.191\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.072\n",
      "fast_reg_loss:0.089\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:04: global_step:9300  current_step:9300\n",
      "speed: 0.343s, remaining training time: 00:02:40:04\n",
      "total_losses:0.413\n",
      "rpn_cls_loss:0.047\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.163\n",
      "fast_reg_loss:0.189\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:11: global_step:9320  current_step:9320\n",
      "speed: 0.326s, remaining training time: 00:02:31:54\n",
      "total_losses:0.315\n",
      "rpn_cls_loss:0.039\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.113\n",
      "fast_reg_loss:0.155\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:27:18: global_step:9340  current_step:9340\n",
      "speed: 0.356s, remaining training time: 00:02:45:48\n",
      "total_losses:0.365\n",
      "rpn_cls_loss:0.060\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.103\n",
      "fast_reg_loss:0.189\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:25: global_step:9360  current_step:9360\n",
      "speed: 0.389s, remaining training time: 00:03:00:58\n",
      "total_losses:0.553\n",
      "rpn_cls_loss:0.056\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.219\n",
      "fast_reg_loss:0.264\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:32: global_step:9380  current_step:9380\n",
      "speed: 0.360s, remaining training time: 00:02:47:29\n",
      "total_losses:0.383\n",
      "rpn_cls_loss:0.043\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.120\n",
      "fast_reg_loss:0.208\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:45: global_step:9420  current_step:9420\n",
      "speed: 0.347s, remaining training time: 00:02:41:10\n",
      "total_losses:0.215\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.054\n",
      "fast_reg_loss:0.114\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:52: global_step:9440  current_step:9440\n",
      "speed: 0.338s, remaining training time: 00:02:36:59\n",
      "total_losses:0.475\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.156\n",
      "fast_reg_loss:0.249\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:27:59: global_step:9460  current_step:9460\n",
      "speed: 0.319s, remaining training time: 00:02:27:53\n",
      "total_losses:0.091\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.028\n",
      "fast_reg_loss:0.037\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:05: global_step:9480  current_step:9480\n",
      "speed: 0.354s, remaining training time: 00:02:44:18\n",
      "total_losses:0.374\n",
      "rpn_cls_loss:0.038\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.118\n",
      "fast_reg_loss:0.211\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:12: global_step:9500  current_step:9500\n",
      "speed: 0.344s, remaining training time: 00:02:39:22\n",
      "total_losses:0.360\n",
      "rpn_cls_loss:0.022\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.129\n",
      "fast_reg_loss:0.201\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:19: global_step:9520  current_step:9520\n",
      "speed: 0.319s, remaining training time: 00:02:27:34\n",
      "total_losses:0.252\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.102\n",
      "fast_reg_loss:0.116\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:25: global_step:9540  current_step:9540\n",
      "speed: 0.334s, remaining training time: 00:02:34:33\n",
      "total_losses:0.265\n",
      "rpn_cls_loss:0.068\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.085\n",
      "fast_reg_loss:0.106\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:32: global_step:9560  current_step:9560\n",
      "speed: 0.354s, remaining training time: 00:02:43:37\n",
      "total_losses:0.402\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.131\n",
      "fast_reg_loss:0.218\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:39: global_step:9580  current_step:9580\n",
      "speed: 0.350s, remaining training time: 00:02:41:55\n",
      "total_losses:0.596\n",
      "rpn_cls_loss:0.049\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.185\n",
      "fast_reg_loss:0.348\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:52: global_step:9620  current_step:9620\n",
      "speed: 0.311s, remaining training time: 00:02:23:41\n",
      "total_losses:0.140\n",
      "rpn_cls_loss:0.012\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.112\n",
      "fast_reg_loss:0.015\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:28:59: global_step:9640  current_step:9640\n",
      "speed: 0.321s, remaining training time: 00:02:28:02\n",
      "total_losses:0.046\n",
      "rpn_cls_loss:0.011\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.019\n",
      "fast_reg_loss:0.013\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:29:05: global_step:9660  current_step:9660\n",
      "speed: 0.338s, remaining training time: 00:02:35:35\n",
      "total_losses:0.403\n",
      "rpn_cls_loss:0.045\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.131\n",
      "fast_reg_loss:0.222\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:29:12: global_step:9680  current_step:9680\n",
      "speed: 0.334s, remaining training time: 00:02:33:57\n",
      "total_losses:0.314\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.096\n",
      "fast_reg_loss:0.167\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:29:20: global_step:9700  current_step:9700\n",
      "speed: 0.328s, remaining training time: 00:02:31:02\n",
      "total_losses:0.327\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.107\n",
      "fast_reg_loss:0.175\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:29:26: global_step:9720  current_step:9720\n",
      "speed: 0.332s, remaining training time: 00:02:32:42\n",
      "total_losses:0.283\n",
      "rpn_cls_loss:0.075\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.080\n",
      "fast_reg_loss:0.120\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:29:33: global_step:9740  current_step:9740\n",
      "speed: 0.321s, remaining training time: 00:02:27:33\n",
      "total_losses:0.257\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.094\n",
      "fast_reg_loss:0.109\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:29:40: global_step:9760  current_step:9760\n",
      "speed: 0.317s, remaining training time: 00:02:25:29\n",
      "total_losses:0.201\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.049\n",
      "fast_reg_loss:0.111\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:29:46: global_step:9780  current_step:9780\n",
      "speed: 0.326s, remaining training time: 00:02:29:19\n",
      "total_losses:0.153\n",
      "rpn_cls_loss:0.019\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.050\n",
      "fast_reg_loss:0.082\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:00: global_step:9820  current_step:9820\n",
      "speed: 0.345s, remaining training time: 00:02:38:11\n",
      "total_losses:0.346\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.109\n",
      "fast_reg_loss:0.202\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:06: global_step:9840  current_step:9840\n",
      "speed: 0.304s, remaining training time: 00:02:19:00\n",
      "total_losses:0.119\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.031\n",
      "fast_reg_loss:0.054\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:13: global_step:9860  current_step:9860\n",
      "speed: 0.343s, remaining training time: 00:02:36:40\n",
      "total_losses:0.448\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.161\n",
      "fast_reg_loss:0.214\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:20: global_step:9880  current_step:9880\n",
      "speed: 0.326s, remaining training time: 00:02:29:10\n",
      "total_losses:0.201\n",
      "rpn_cls_loss:0.029\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.065\n",
      "fast_reg_loss:0.100\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:26: global_step:9900  current_step:9900\n",
      "speed: 0.348s, remaining training time: 00:02:38:59\n",
      "total_losses:0.329\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.102\n",
      "fast_reg_loss:0.175\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:33: global_step:9920  current_step:9920\n",
      "speed: 0.358s, remaining training time: 00:02:43:28\n",
      "total_losses:0.335\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.107\n",
      "fast_reg_loss:0.167\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:40: global_step:9940  current_step:9940\n",
      "speed: 0.369s, remaining training time: 00:02:48:20\n",
      "total_losses:0.630\n",
      "rpn_cls_loss:0.162\n",
      "rpn_reg_loss:0.020\n",
      "fast_cls_loss:0.191\n",
      "fast_reg_loss:0.258\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:46: global_step:9960  current_step:9960\n",
      "speed: 0.317s, remaining training time: 00:02:24:28\n",
      "total_losses:0.316\n",
      "rpn_cls_loss:0.064\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.114\n",
      "fast_reg_loss:0.134\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:30:53: global_step:9980  current_step:9980\n",
      "speed: 0.341s, remaining training time: 00:02:35:25\n",
      "total_losses:0.346\n",
      "rpn_cls_loss:0.059\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.119\n",
      "fast_reg_loss:0.159\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:07: global_step:10020  current_step:10020\n",
      "speed: 0.302s, remaining training time: 00:02:17:22\n",
      "total_losses:0.100\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.031\n",
      "fast_reg_loss:0.045\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:14: global_step:10040  current_step:10040\n",
      "speed: 0.339s, remaining training time: 00:02:34:00\n",
      "total_losses:0.320\n",
      "rpn_cls_loss:0.036\n",
      "rpn_reg_loss:0.012\n",
      "fast_cls_loss:0.098\n",
      "fast_reg_loss:0.174\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:21: global_step:10060  current_step:10060\n",
      "speed: 0.342s, remaining training time: 00:02:35:10\n",
      "total_losses:0.457\n",
      "rpn_cls_loss:0.039\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.186\n",
      "fast_reg_loss:0.224\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:31:28: global_step:10080  current_step:10080\n",
      "speed: 0.328s, remaining training time: 00:02:28:53\n",
      "total_losses:0.198\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.085\n",
      "fast_reg_loss:0.080\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:35: global_step:10100  current_step:10100\n",
      "speed: 0.354s, remaining training time: 00:02:40:22\n",
      "total_losses:0.335\n",
      "rpn_cls_loss:0.034\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.099\n",
      "fast_reg_loss:0.192\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:42: global_step:10120  current_step:10120\n",
      "speed: 0.366s, remaining training time: 00:02:45:36\n",
      "total_losses:0.503\n",
      "rpn_cls_loss:0.097\n",
      "rpn_reg_loss:0.015\n",
      "fast_cls_loss:0.176\n",
      "fast_reg_loss:0.215\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:48: global_step:10140  current_step:10140\n",
      "speed: 0.339s, remaining training time: 00:02:33:38\n",
      "total_losses:0.329\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.094\n",
      "fast_reg_loss:0.177\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:31:55: global_step:10160  current_step:10160\n",
      "speed: 0.333s, remaining training time: 00:02:30:27\n",
      "total_losses:0.188\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.062\n",
      "fast_reg_loss:0.080\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:01: global_step:10180  current_step:10180\n",
      "speed: 0.318s, remaining training time: 00:02:23:48\n",
      "total_losses:0.188\n",
      "rpn_cls_loss:0.046\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.069\n",
      "fast_reg_loss:0.068\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:15: global_step:10220  current_step:10220\n",
      "speed: 0.366s, remaining training time: 00:02:45:24\n",
      "total_losses:0.486\n",
      "rpn_cls_loss:0.057\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.127\n",
      "fast_reg_loss:0.287\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:22: global_step:10240  current_step:10240\n",
      "speed: 0.363s, remaining training time: 00:02:43:48\n",
      "total_losses:0.386\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.118\n",
      "fast_reg_loss:0.219\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:28: global_step:10260  current_step:10260\n",
      "speed: 0.341s, remaining training time: 00:02:33:51\n",
      "total_losses:0.236\n",
      "rpn_cls_loss:0.030\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.095\n",
      "fast_reg_loss:0.101\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:35: global_step:10280  current_step:10280\n",
      "speed: 0.329s, remaining training time: 00:02:28:16\n",
      "total_losses:0.339\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.116\n",
      "fast_reg_loss:0.184\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:42: global_step:10300  current_step:10300\n",
      "speed: 0.307s, remaining training time: 00:02:18:18\n",
      "total_losses:0.098\n",
      "rpn_cls_loss:0.031\n",
      "rpn_reg_loss:0.001\n",
      "fast_cls_loss:0.023\n",
      "fast_reg_loss:0.042\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:48: global_step:10320  current_step:10320\n",
      "speed: 0.314s, remaining training time: 00:02:21:18\n",
      "total_losses:0.306\n",
      "rpn_cls_loss:0.072\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.100\n",
      "fast_reg_loss:0.125\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:32:55: global_step:10340  current_step:10340\n",
      "speed: 0.363s, remaining training time: 00:02:42:53\n",
      "total_losses:0.526\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:0.162\n",
      "fast_reg_loss:0.303\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:02: global_step:10360  current_step:10360\n",
      "speed: 0.335s, remaining training time: 00:02:30:33\n",
      "total_losses:0.157\n",
      "rpn_cls_loss:0.020\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.041\n",
      "fast_reg_loss:0.093\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:08: global_step:10380  current_step:10380\n",
      "speed: 0.351s, remaining training time: 00:02:37:22\n",
      "total_losses:0.310\n",
      "rpn_cls_loss:0.051\n",
      "rpn_reg_loss:0.006\n",
      "fast_cls_loss:0.090\n",
      "fast_reg_loss:0.163\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:22: global_step:10420  current_step:10420\n",
      "speed: 0.330s, remaining training time: 00:02:27:44\n",
      "total_losses:0.240\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.107\n",
      "fast_reg_loss:0.115\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:28: global_step:10440  current_step:10440\n",
      "speed: 0.357s, remaining training time: 00:02:39:49\n",
      "total_losses:0.282\n",
      "rpn_cls_loss:0.044\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.098\n",
      "fast_reg_loss:0.131\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:33:36: global_step:10460  current_step:10460\n",
      "speed: 0.316s, remaining training time: 00:02:21:21\n",
      "total_losses:0.141\n",
      "rpn_cls_loss:0.032\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.041\n",
      "fast_reg_loss:0.064\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:43: global_step:10480  current_step:10480\n",
      "speed: 0.330s, remaining training time: 00:02:27:32\n",
      "total_losses:0.223\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.083\n",
      "fast_reg_loss:0.109\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:49: global_step:10500  current_step:10500\n",
      "speed: 0.316s, remaining training time: 00:02:21:02\n",
      "total_losses:0.048\n",
      "rpn_cls_loss:0.016\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.016\n",
      "fast_reg_loss:0.014\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:33:56: global_step:10520  current_step:10520\n",
      "speed: 0.310s, remaining training time: 00:02:18:12\n",
      "total_losses:0.242\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.071\n",
      "fast_reg_loss:0.134\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:03: global_step:10540  current_step:10540\n",
      "speed: 0.309s, remaining training time: 00:02:17:43\n",
      "total_losses:0.128\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.003\n",
      "fast_cls_loss:0.041\n",
      "fast_reg_loss:0.066\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:09: global_step:10560  current_step:10560\n",
      "speed: 0.330s, remaining training time: 00:02:26:54\n",
      "total_losses:0.338\n",
      "rpn_cls_loss:0.041\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.142\n",
      "fast_reg_loss:0.142\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:16: global_step:10580  current_step:10580\n",
      "speed: 0.340s, remaining training time: 00:02:31:13\n",
      "total_losses:0.386\n",
      "rpn_cls_loss:0.025\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.132\n",
      "fast_reg_loss:0.221\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:29: global_step:10620  current_step:10620\n",
      "speed: 0.320s, remaining training time: 00:02:22:29\n",
      "total_losses:0.125\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.038\n",
      "fast_reg_loss:0.063\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:36: global_step:10640  current_step:10640\n",
      "speed: 0.327s, remaining training time: 00:02:25:15\n",
      "total_losses:0.260\n",
      "rpn_cls_loss:0.056\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.116\n",
      "fast_reg_loss:0.084\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:42: global_step:10660  current_step:10660\n",
      "speed: 0.327s, remaining training time: 00:02:25:09\n",
      "total_losses:0.200\n",
      "rpn_cls_loss:0.028\n",
      "rpn_reg_loss:0.008\n",
      "fast_cls_loss:0.067\n",
      "fast_reg_loss:0.097\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:49: global_step:10680  current_step:10680\n",
      "speed: 0.337s, remaining training time: 00:02:29:41\n",
      "total_losses:0.660\n",
      "rpn_cls_loss:0.112\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.216\n",
      "fast_reg_loss:0.319\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:34:56: global_step:10700  current_step:10700\n",
      "speed: 0.317s, remaining training time: 00:02:20:28\n",
      "total_losses:0.206\n",
      "rpn_cls_loss:0.039\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.056\n",
      "fast_reg_loss:0.104\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:02: global_step:10720  current_step:10720\n",
      "speed: 0.318s, remaining training time: 00:02:20:47\n",
      "total_losses:0.073\n",
      "rpn_cls_loss:0.019\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.023\n",
      "fast_reg_loss:0.026\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:09: global_step:10740  current_step:10740\n",
      "speed: 0.331s, remaining training time: 00:02:26:37\n",
      "total_losses:0.310\n",
      "rpn_cls_loss:0.075\n",
      "rpn_reg_loss:0.009\n",
      "fast_cls_loss:0.090\n",
      "fast_reg_loss:0.137\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:16: global_step:10760  current_step:10760\n",
      "speed: 0.331s, remaining training time: 00:02:26:18\n",
      "total_losses:0.486\n",
      "rpn_cls_loss:0.037\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.176\n",
      "fast_reg_loss:0.267\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:22: global_step:10780  current_step:10780\n",
      "speed: 0.333s, remaining training time: 00:02:27:21\n",
      "total_losses:0.410\n",
      "rpn_cls_loss:0.052\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.150\n",
      "fast_reg_loss:0.197\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2022-08-21 21:35:37: global_step:10820  current_step:10820\n",
      "speed: 0.366s, remaining training time: 00:02:41:28\n",
      "total_losses:0.532\n",
      "rpn_cls_loss:0.096\n",
      "rpn_reg_loss:0.018\n",
      "fast_cls_loss:0.178\n",
      "fast_reg_loss:0.240\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:43: global_step:10840  current_step:10840\n",
      "speed: 0.332s, remaining training time: 00:02:26:15\n",
      "total_losses:0.231\n",
      "rpn_cls_loss:0.067\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.056\n",
      "fast_reg_loss:0.103\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:50: global_step:10860  current_step:10860\n",
      "speed: 0.327s, remaining training time: 00:02:23:55\n",
      "total_losses:0.183\n",
      "rpn_cls_loss:0.023\n",
      "rpn_reg_loss:0.005\n",
      "fast_cls_loss:0.056\n",
      "fast_reg_loss:0.099\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:35:57: global_step:10880  current_step:10880\n",
      "speed: 0.343s, remaining training time: 00:02:31:12\n",
      "total_losses:0.366\n",
      "rpn_cls_loss:0.042\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.121\n",
      "fast_reg_loss:0.192\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:03: global_step:10900  current_step:10900\n",
      "speed: 0.312s, remaining training time: 00:02:17:16\n",
      "total_losses:0.199\n",
      "rpn_cls_loss:0.033\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.058\n",
      "fast_reg_loss:0.104\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:10: global_step:10920  current_step:10920\n",
      "speed: 0.316s, remaining training time: 00:02:18:44\n",
      "total_losses:0.233\n",
      "rpn_cls_loss:0.035\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.093\n",
      "fast_reg_loss:0.098\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:16: global_step:10940  current_step:10940\n",
      "speed: 0.321s, remaining training time: 00:02:20:53\n",
      "total_losses:0.222\n",
      "rpn_cls_loss:0.018\n",
      "rpn_reg_loss:0.004\n",
      "fast_cls_loss:0.104\n",
      "fast_reg_loss:0.096\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:23: global_step:10960  current_step:10960\n",
      "speed: 0.314s, remaining training time: 00:02:17:41\n",
      "total_losses:0.157\n",
      "rpn_cls_loss:0.015\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.065\n",
      "fast_reg_loss:0.074\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:30: global_step:10980  current_step:10980\n",
      "speed: 0.331s, remaining training time: 00:02:25:10\n",
      "total_losses:0.477\n",
      "rpn_cls_loss:0.075\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.185\n",
      "fast_reg_loss:0.208\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:43: global_step:11020  current_step:11020\n",
      "speed: 0.371s, remaining training time: 00:02:42:28\n",
      "total_losses:0.658\n",
      "rpn_cls_loss:0.069\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.251\n",
      "fast_reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:50: global_step:11040  current_step:11040\n",
      "speed: 0.336s, remaining training time: 00:02:27:11\n",
      "total_losses:0.318\n",
      "rpn_cls_loss:0.074\n",
      "rpn_reg_loss:0.010\n",
      "fast_cls_loss:0.109\n",
      "fast_reg_loss:0.125\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:36:56: global_step:11060  current_step:11060\n",
      "speed: 0.368s, remaining training time: 00:02:40:52\n",
      "total_losses:0.519\n",
      "rpn_cls_loss:0.095\n",
      "rpn_reg_loss:0.014\n",
      "fast_cls_loss:0.173\n",
      "fast_reg_loss:0.236\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:37:03: global_step:11080  current_step:11080\n",
      "speed: 0.359s, remaining training time: 00:02:36:46\n",
      "total_losses:0.693\n",
      "rpn_cls_loss:0.104\n",
      "rpn_reg_loss:0.016\n",
      "fast_cls_loss:0.292\n",
      "fast_reg_loss:0.282\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:37:10: global_step:11100  current_step:11100\n",
      "speed: 0.344s, remaining training time: 00:02:30:00\n",
      "total_losses:0.309\n",
      "rpn_cls_loss:0.054\n",
      "rpn_reg_loss:0.007\n",
      "fast_cls_loss:0.097\n",
      "fast_reg_loss:0.152\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:37:16: global_step:11120  current_step:11120\n",
      "speed: 0.358s, remaining training time: 00:02:36:13\n",
      "total_losses:0.683\n",
      "rpn_cls_loss:0.071\n",
      "rpn_reg_loss:0.013\n",
      "fast_cls_loss:0.206\n",
      "fast_reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:37:23: global_step:11140  current_step:11140\n",
      "speed: 0.332s, remaining training time: 00:02:24:40\n",
      "total_losses:0.373\n",
      "rpn_cls_loss:0.026\n",
      "rpn_reg_loss:0.011\n",
      "fast_cls_loss:0.143\n",
      "fast_reg_loss:0.193\n",
      "\n",
      "************************************************************************\n",
      "2022-08-21 21:37:30: global_step:11160  current_step:11160\n",
      "speed: 0.316s, remaining training time: 00:02:17:44\n",
      "total_losses:0.113\n",
      "rpn_cls_loss:0.022\n",
      "rpn_reg_loss:0.002\n",
      "fast_cls_loss:0.028\n",
      "fast_reg_loss:0.061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change the path to the detector!\n",
    "%cd /workdir/SW/RotationDetection/tools/r2cnn\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "| Model      | AP50 normal | AP50 mitoses | P50 normal | R50 normal | P50 mitoses | R50 mitoses |   AP50    |   AP75    |   AP50:95   |\n",
    "|----------- | ----------- | ------------ | ---------- | ---------- | ----------- | ----------- |   -----   |   -----   |   -------   |\n",
    "| RetinaNet  |   75.25     |   56.47      | 37.64      | 85.00      | 10.99       | 82.85       |   65.86   |   19.17   |   29.56     |\n",
    "| R3Det      |   74.97     |   63.21      | 32.68      | 83.42      | 14.35       | 84.76       |   69.09   |   17.91   |   30.89     |\n",
    "| R3Det DCL  |   75.50     |   62.63      | 31.58      | 83.54      | 15.75       | 84.76       |   69.06   | **20.57** |   30.73     |\n",
    "| DCL        |   71.81     |   63.35      | 39.58      | 81.62      | 16.50       | 80.95       |   67.58   |   17.74   |   28.48     |\n",
    "| CSL        |   72.42     |   53.98      | 35.20      | 84.10      | 10.94       | 84.76       |   63.20   |   18.59   |   27.00     |\n",
    "| R2CNN      | **77.33**   | **69.65**    | **67.49**  | 82.41      | **52.79**   | 80.95       | **73.49** |   17.30   |   29.71     |\n",
    "| Refine RetinaNet | 75.15 |   66.75      | 27.93      | **85.68**  | 11.94       | **89.52**   |   70.95   |   18.86   | **31.00**   |\n",
    "| RSDet      |   74.33     |   63.60      | 38.65      | 83.31      | 9.63        | 87.62       |   68.97   |   16.15   |   29.86     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/SW/RotationDetection/tools/r2cnn\n",
      "/workdir/SW/RotationDetection\n",
      "model restore from : /workdir/SW/RotationDetection/output/trained_weights/R2CNN_Fluo-N2DH-SIM+-all_smooth_l1_loss/UFRGS_CELL_1class_37299model.ckpt\n",
      "\n",
      "**********\n",
      "Restored model\n",
      "/workdir/SW/RotationDetection/output/trained_weights/R2CNN_Fluo-N2DH-SIM+-all_smooth_l1_loss/UFRGS_CELL_1class_37299model.ckpt\n",
      "**********\n",
      "Eval image t029_0261_0227: 100%|████████████| 2400/2400 [01:48<00:00, 22.14it/s]\n",
      "********************\n",
      "rotation eval:\n",
      "Threshold:  0.5\n",
      "cls : normal_cell|| Recall: 0.8548566347760667 || Precison: 0.9158596602635339|| AP: 0.8044326603736205\n",
      "mAP is : 0.8044326603736205\n",
      "\n",
      "\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"test_ufrgscell.py\", line 106, in <module>\n",
      "    tester.eval()\n",
      "  File \"test_ufrgscell.py\", line 100, in eval\n",
      "    test_annotation_path=self.args.test_annotation_path)\n",
      "  File \"../../libs/val_libs/voc_eval_r.py\", line 324, in voc_evaluate_detections\n",
      "    ap,prec,rec = self.do_python_eval(test_imgid_list, test_annotation_path, ovthreshold=th, verbose=verbose)\n",
      "  File \"../../libs/val_libs/voc_eval_r.py\", line 267, in do_python_eval\n",
      "    ovthresh=ovthreshold)\n",
      "  File \"../../libs/val_libs/voc_eval_r.py\", line 199, in voc_eval\n",
      "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
      "  File \"../../libs/val_libs/voc_eval_r.py\", line 199, in <listcomp>\n",
      "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
      "  File \"../../libs/val_libs/voc_eval_r.py\", line 199, in <listcomp>\n",
      "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /workdir/SW/RotationDetection/tools/r2cnn\n",
    "!python test_ufrgscell.py --img_dir='/workdir/Fluo-N2DH-SIM+/02/crop/images'  \\\n",
    "                          --gpu=0 \\\n",
    "                          --image_ext='.png' \\\n",
    "                          --test_annotation_path='/workdir/Fluo-N2DH-SIM+/02/crop/labeltxt' \\\n",
    "                          none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_labels = '/workdir/datasets/msc/UFRGS_CELL_2classes/test/annotations/dota_format'\n",
    "path_draws = '/workdir/msc/RotationDetection/tools/gwd/test_ufrgscell/RetinaNet_UFRGS_CELL_smooth_l1_loss/ufrgscell_img_vis'\n",
    "\n",
    "path_labels = sorted(glob(os.path.join(path_labels, '*.txt')))\n",
    "path_draws  = sorted(glob(os.path.join(path_draws, '*.jpg')))\n",
    "\n",
    "for i in range(len(path_labels)):\n",
    "    path_ann = path_labels[i]\n",
    "    path_img = path_draws[i]\n",
    "\n",
    "    img = cv2.imread(path_img)[:,:,::-1]\n",
    "    h,w,c = img.shape\n",
    "\n",
    "    labels = []\n",
    "    for lb in open(path_ann, 'r').read().split('\\n')[2:-1]:\n",
    "        lb = np.reshape(list(map(float, lb.split(' ')[:-2])), (-1,2))\n",
    "        labels.append(lb)\n",
    "    labels = np.int0(labels)\n",
    "    \n",
    "    draw = np.copy(img)\n",
    "    cv2.drawContours(draw, labels, -1, (255,0,0), 2)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET='Fluo-N2DL-HeLa'\n",
    "LINEAGE='02'\n",
    "\n",
    "!cp -r /workdir/pepper-experiments/models/msc/datasets/{DATASET}/{LINEAGE}/crop/labeltxt \\\n",
    "/workdir/pepper-experiments/models/msc/ISBI/{DATASET}/{LINEAGE}/crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
